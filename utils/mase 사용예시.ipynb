{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9f9c28df4de0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'i_call_x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'i_call_y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'i_call_y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mone_hot_train_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mone_hot_train_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 해당 소스는 예시이며, one_hot_train과 one_hot_test의 부분은 본인들의 data set으로 활용해야함\n",
    "\n",
    "'''\n",
    "예를들어, 7일전 24시간 온도로 오늘 24시간 온도를 예측하는 모델이라면,\n",
    "i_call_x : 이전 기간의 온도값 (24시간어치)\n",
    "i_call_y : 오늘 기간의 온도값 (24시간어치)\n",
    "'''\n",
    "# 이와 같이 mase에 실제 정답값으로 값을 전달하여 사용하게됨.\n",
    "\n",
    "y_columns = ['i_call_x','i_call_y']\n",
    "x_columns = list(set(one_hot_train.columns) - set(['i_call_y']))\n",
    "\n",
    "one_hot_train_x = one_hot_train[x_columns]\n",
    "one_hot_train_y = one_hot_train[y_columns]\n",
    "one_hot_test_x = one_hot_test[x_columns]\n",
    "one_hot_test_y = one_hot_test[y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, ReLU, TimeDistributed, Bidirectional, RepeatVector\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 24, 1024)          4239360   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 24, 512)           3147776   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 24, 1)             513       \n",
      "=================================================================\n",
      "Total params: 7,387,649\n",
      "Trainable params: 7,387,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1024, return_sequences=True, input_shape=(24,10)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot_train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b689e29522ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 상위 모듈에서 이미 작성된 소스로 y_true와 y_pred는 자동으로 모델에서 넘어가기때문에, 넘겨주는 값으로만 잘 설정해주면 소스 동작에는 이상이 없음.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_train_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot_train_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot_train_x' is not defined"
     ]
    }
   ],
   "source": [
    "from custom_loss_2_true import custom_loss\n",
    "\n",
    "# 실제 모델 활용 예시\n",
    "loss = custom_loss()\n",
    "# 상위 모듈에서 이미 작성된 소스로 y_true와 y_pred는 자동으로 모델에서 넘어가기때문에, 넘겨주는 값으로만 잘 설정해주면 소스 동작에는 이상이 없음.\n",
    "model.compile(loss=loss.mase, optimizer=Adam(lr=0.001))\n",
    "model.fit(one_hot_train_x.values, one_hot_train_y.values, batch_size=200, epochs=3000, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "만약 필자의 mase 소스를 수정하여, 더 많은 값을 활용하고 싶다면\n",
    "@tf.function\n",
    "train_step을 사용하여 직접 loss에 들어가는 값들을 관장해주어야함.\n",
    "'''\n",
    "\n",
    "# 아래의 소스를 활용하여 수정할 수 있겠음. 필자는 현재 이렇게 사용하고 있지는 않아서, 사용하게 될 시에 추가하여 올리도록 하겠음.\n",
    "@tf.function\n",
    "def train_step(inputs,labels,loss_fn,optimizer):\n",
    "    loss = 0\n",
    "    encoder_input, decoder_input = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden, enc_c = encoder(encoder_input)\n",
    "\n",
    "        for t in range(0, decoder_input.shape[1]):\n",
    "            dec_input = tf.reshape(decoder_input[:,t],(-1,1,decoder_input.shape[2]))\n",
    "            predictions, attention_weights = decoder(dec_input, enc_output, enc_hidden, enc_c)\n",
    "            loss += loss_fn(tf.reshape(labels[:,t],(-1,1,1)), predictions)\n",
    "    batch_loss = tf.reduce_mean(loss)\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss,variables)\n",
    "    optimizer.apply_gradients(zip(gradients,variables))\n",
    "\n",
    "    return batch_loss\n",
    "\n",
    "loss_fn = loss\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
