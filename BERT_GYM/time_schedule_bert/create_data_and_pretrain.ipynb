{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# modeling은 직접 수정한(position, token embedding을 뺀), 모델로 사용할 것이므로, salt_bert를 활용하면 안됩니다.\n",
    "import modeling\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from salt_bert.make_preprocessed_data import tokenization\n",
    "from salt_bert.make_bert_model import optimization\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "\n",
    "random_seed=777\n",
    "rng = random.Random(random_seed)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[0],'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "\n",
    "dupe_factor = 100\n",
    "masked_lm_prob=0.8\n",
    "max_predictions_per_seq=4\n",
    "max_seq_length = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# masked 처리\n",
    "def create_masked_lm_predictions(tokens, vocab_words, masked_lm_prob=0.15, max_predictions_per_seq=20, rng=rng):\n",
    "    \"\"\"Creates the predictions for the masked LM objective.\"\"\"\n",
    "\n",
    "    cand_indexes = []\n",
    "    for (i, token) in enumerate(tokens):\t\t\t# [MASK] 를 삽입할 token 후보 리스트를 생성\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        cand_indexes.append(i)\n",
    "\n",
    "    rng.shuffle(cand_indexes)\n",
    "\n",
    "    output_tokens = list(tokens)\n",
    "\n",
    "    masked_lm = collections.namedtuple(\"masked_lm\", [\"index\", \"label\"])    # pylint: disable=invalid-name\n",
    "\n",
    "    num_to_predict = min(max_predictions_per_seq,\t\t\t\t\t# [MASK] 를 삽입할 token의 개수를 현재 token 중에서 15%의 확률로 선택 \n",
    "                                             max(1, int(round(len(tokens) * masked_lm_prob))))\t# 만약 그 값이 20보다 크다면, 20개의 token만 [MASK]로 변환\n",
    "\n",
    "    masked_lms = []\n",
    "    covered_indexes = set()\n",
    "    for index in cand_indexes:\n",
    "        if len(masked_lms) >= num_to_predict:\t\t\t\t\t# 앞에서 지정한 개수 만큼한 [MASK]\n",
    "            break\n",
    "        if index in covered_indexes:\n",
    "            continue\n",
    "        covered_indexes.add(index)\n",
    "\n",
    "        masked_token = None\n",
    "        # 80% of the time, replace with [MASK]\n",
    "        if rng.random() < 0.8:\t\t\t\t\t\t\t# 그 중, 80%는 [MASK]로 변환\n",
    "            masked_token = \"[MASK]\"\n",
    "        else:\n",
    "            # 10% of the time, keep original\n",
    "            if rng.random() < 0.5:\t\t\t\t\t\t\t# 나머지 20%의 확률 중, 절반인 10%는 원본 유지\n",
    "                masked_token = tokens[index]\n",
    "            # 10% of the time, replace with random word\n",
    "            else:\t\t\t\t\t\t\t\t\t# 나머지 10%는 랜덤으로 replace\n",
    "                masked_token = vocab_words[rng.randint(0, len(vocab_words) - 1)]\n",
    "\n",
    "        output_tokens[index] = masked_token\n",
    "\n",
    "        masked_lms.append(masked_lm(index=index, label=tokens[index]))\n",
    "\n",
    "    masked_lms = sorted(masked_lms, key=lambda x: x.index)\n",
    "\n",
    "    masked_lm_positions = []\n",
    "    masked_lm_labels = []\n",
    "    for p in masked_lms:\n",
    "        masked_lm_positions.append(p.index)\n",
    "        masked_lm_labels.append(p.label)\n",
    "\n",
    "    return (output_tokens, masked_lm_positions, masked_lm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 생성\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# 로그의 출력 기준 설정\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# log 출력 형식\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# log 출력\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "# log를 파일에 출력\n",
    "# file_handler = logging.FileHandler('my.log')\n",
    "# file_handler.setFormatter(formatter)\n",
    "# logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "target_strt_date_dt='2020-01-01'\n",
    "target_strt_str_dt=target_strt_date_dt.replace('-','')\n",
    "target_end_date_dt='2022-01-01'\n",
    "target_end_str_dt=target_end_date_dt.replace('-','')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   str_ymd   731 non-null    object\n",
      " 1   year      731 non-null    int64 \n",
      " 2   mon       731 non-null    int64 \n",
      " 3   day       731 non-null    int64 \n",
      " 4   day_kor   731 non-null    object\n",
      " 5   weekend   731 non-null    object\n",
      " 6   holiday   731 non-null    object\n",
      " 7   str_duty  731 non-null    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터는 직접 불러와주세요\n",
    "\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 전처리를 진행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingInstance(object):\n",
    "    \"\"\"A single training instance (sentence pair).\"\"\"\n",
    "\n",
    "    def __init__(self, tokens, masked_lm_positions, masked_lm_labels):\n",
    "        self.tokens = tokens\n",
    "        self.masked_lm_positions = masked_lm_positions\n",
    "        self.masked_lm_labels = masked_lm_labels\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"\"\n",
    "        s += \"tokens: %s\\n\" % (\" \".join(\n",
    "                [tokenization.printable_text(x) for x in self.tokens]))\n",
    "        s += \"masked_lm_positions: %s\\n\" % (\" \".join(\n",
    "                [str(x) for x in self.masked_lm_positions]))\n",
    "        s += \"masked_lm_labels: %s\\n\" % (\" \".join(\n",
    "                [tokenization.printable_text(x) for x in self.masked_lm_labels]))\n",
    "        s += \"\\n\"\n",
    "        return s\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    \n",
    "def create_float_feature(values):\n",
    "    feature = tf.train.Feature(float_list=tf.train.FloatList(value=list(values)))\n",
    "    return feature\n",
    "\n",
    "def create_int_feature(values):\n",
    "    feature = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
    "    return feature\n",
    "    \n",
    "def write_instance_to_example_files(instances, tokenizer, max_seq_length, max_predictions_per_seq, output_files):\n",
    "    \"\"\"Create TF example files from `TrainingInstance`s.\"\"\"\n",
    "    writers = []\n",
    "    for output_file in output_files:\n",
    "        writers.append(tf.io.TFRecordWriter(output_file))\n",
    "\n",
    "    writer_index = 0\n",
    "\n",
    "    total_written = 0\n",
    "    for (inst_index, instance) in enumerate(instances):\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(instance.tokens)\n",
    "        assert len(input_ids) <= max_seq_length\n",
    "\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "\n",
    "        masked_lm_positions = list(instance.masked_lm_positions)\n",
    "        masked_lm_ids = tokenizer.convert_tokens_to_ids(instance.masked_lm_labels)\n",
    "        masked_lm_weights = [1.0] * len(masked_lm_ids)\n",
    "\n",
    "        while len(masked_lm_positions) < max_predictions_per_seq:\n",
    "            masked_lm_positions.append(0)\n",
    "            masked_lm_ids.append(0)\n",
    "            masked_lm_weights.append(0.0)\n",
    "\n",
    "        features = collections.OrderedDict()\n",
    "        features[\"input_ids\"] = create_int_feature(input_ids)\n",
    "        features[\"masked_lm_positions\"] = create_int_feature(masked_lm_positions)\n",
    "        features[\"masked_lm_ids\"] = create_int_feature(masked_lm_ids)\n",
    "        features[\"masked_lm_weights\"] = create_float_feature(masked_lm_weights)\n",
    "\n",
    "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "        writers[writer_index].write(tf_example.SerializeToString())\n",
    "        writer_index = (writer_index + 1) % len(writers)\n",
    "\n",
    "        total_written += 1\n",
    "\n",
    "        if inst_index < 20:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"tokens: %s\" % \" \".join([tokenization.printable_text(x) for x in instance.tokens]))\n",
    "\n",
    "            for feature_name in features.keys():\n",
    "                feature = features[feature_name]\n",
    "                values = []\n",
    "                if feature.int64_list.value:\n",
    "                    values = feature.int64_list.value\n",
    "                elif feature.float_list.value:\n",
    "                    values = feature.float_list.value\n",
    "                logger.info(\"%s: %s\" % (feature_name, \" \".join([str(x) for x in values])))\n",
    "\n",
    "    for writer in writers:\n",
    "        writer.close()\n",
    "\n",
    "    logger.info(\"Wrote %d total instances\", total_written)\n",
    "    \n",
    "def create_instances_from_document(\n",
    "        all_documents, document_index, masked_lm_prob, max_predictions_per_seq, vocab_words, rng):\n",
    "    \"\"\"Creates `TrainingInstance`s for a single document.\"\"\"\n",
    "    document = all_documents[document_index]\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    i = 0\n",
    "    \n",
    "    input_token = []\n",
    "    # CLS/SEP 제외\n",
    "    # input_token.append(\"[CLS]\")\n",
    "    input_token.extend(document)\n",
    "    # input_token.append(\"[SEP]\")\n",
    "\n",
    "    (tokens, masked_lm_positions,\n",
    "     masked_lm_labels) = create_masked_lm_predictions(input_token, vocab_words, masked_lm_prob, max_predictions_per_seq, rng)\t\t# 만들어진 전체 sequence의 특정 token index에 [MASK] 를 수행\n",
    "    instance = TrainingInstance(\n",
    "            tokens=input_token,\n",
    "            masked_lm_positions=masked_lm_positions,\n",
    "            masked_lm_labels=masked_lm_labels)\n",
    "    instances.append(instance)\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = # pre training에 사용될 feature값\n",
    "# vocab.list는 직접 만들어주셔야 합니다. 데이터는 제공되지 않아요!\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file='./vocab.list', do_lower_case=False)\n",
    "vocab_words = list(tokenizer.vocab.keys())\n",
    "\n",
    "instances = []\n",
    "for _ in range(dupe_factor):\n",
    "    for document_index in range(len(train_features)):\n",
    "        instances.extend(\n",
    "                create_instances_from_document(\n",
    "                        train_features, document_index, masked_lm_prob, max_predictions_per_seq, vocab_words, rng))\n",
    "rng.shuffle(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:12,466 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,467 - root - INFO - tokens: N O O D D E O\n",
      "2022-01-19 14:23:12,467 - root - INFO - input_ids: 5 6 6 3 3 4 6\n",
      "2022-01-19 14:23:12,468 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,468 - root - INFO - masked_lm_positions: 0 3 4 6\n",
      "2022-01-19 14:23:12,468 - root - INFO - masked_lm_ids: 5 3 3 6\n",
      "2022-01-19 14:23:12,469 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,470 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,470 - root - INFO - tokens: E O N N O O D\n",
      "2022-01-19 14:23:12,470 - root - INFO - input_ids: 4 6 5 5 6 6 3\n",
      "2022-01-19 14:23:12,470 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,471 - root - INFO - masked_lm_positions: 1 3 4 5\n",
      "2022-01-19 14:23:12,471 - root - INFO - masked_lm_ids: 6 5 6 6\n",
      "2022-01-19 14:23:12,471 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,472 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,472 - root - INFO - tokens: D O E E E E O\n",
      "2022-01-19 14:23:12,473 - root - INFO - input_ids: 3 6 4 4 4 4 6\n",
      "2022-01-19 14:23:12,473 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,473 - root - INFO - masked_lm_positions: 1 2 4 6\n",
      "2022-01-19 14:23:12,473 - root - INFO - masked_lm_ids: 6 4 4 6\n",
      "2022-01-19 14:23:12,474 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,474 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,475 - root - INFO - tokens: D D D N O O E\n",
      "2022-01-19 14:23:12,475 - root - INFO - input_ids: 3 3 3 5 6 6 4\n",
      "2022-01-19 14:23:12,475 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,476 - root - INFO - masked_lm_positions: 0 2 4 5\n",
      "2022-01-19 14:23:12,476 - root - INFO - masked_lm_ids: 3 3 6 6\n",
      "2022-01-19 14:23:12,476 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,477 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,477 - root - INFO - tokens: O D D E O N O\n",
      "2022-01-19 14:23:12,478 - root - INFO - input_ids: 6 3 3 4 6 5 6\n",
      "2022-01-19 14:23:12,478 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,479 - root - INFO - masked_lm_positions: 0 1 4 6\n",
      "2022-01-19 14:23:12,479 - root - INFO - masked_lm_ids: 6 3 6 6\n",
      "2022-01-19 14:23:12,479 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,480 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,480 - root - INFO - tokens: E E E N O O D\n",
      "2022-01-19 14:23:12,480 - root - INFO - input_ids: 4 4 4 5 6 6 3\n",
      "2022-01-19 14:23:12,481 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,481 - root - INFO - masked_lm_positions: 1 2 5 6\n",
      "2022-01-19 14:23:12,481 - root - INFO - masked_lm_ids: 4 4 6 3\n",
      "2022-01-19 14:23:12,481 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,482 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,482 - root - INFO - tokens: D O E E E E O\n",
      "2022-01-19 14:23:12,483 - root - INFO - input_ids: 3 6 4 4 4 4 6\n",
      "2022-01-19 14:23:12,483 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,483 - root - INFO - masked_lm_positions: 1 2 3 5\n",
      "2022-01-19 14:23:12,483 - root - INFO - masked_lm_ids: 6 4 4 4\n",
      "2022-01-19 14:23:12,484 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,484 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,485 - root - INFO - tokens: E E O D O E E\n",
      "2022-01-19 14:23:12,485 - root - INFO - input_ids: 4 4 6 3 6 4 4\n",
      "2022-01-19 14:23:12,485 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,485 - root - INFO - masked_lm_positions: 0 2 3 6\n",
      "2022-01-19 14:23:12,486 - root - INFO - masked_lm_ids: 4 6 3 4\n",
      "2022-01-19 14:23:12,486 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,487 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,487 - root - INFO - tokens: D D D N O O E\n",
      "2022-01-19 14:23:12,487 - root - INFO - input_ids: 3 3 3 5 6 6 4\n",
      "2022-01-19 14:23:12,487 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,487 - root - INFO - masked_lm_positions: 0 1 4 6\n",
      "2022-01-19 14:23:12,488 - root - INFO - masked_lm_ids: 3 3 6 4\n",
      "2022-01-19 14:23:12,488 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,489 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,489 - root - INFO - tokens: N N O O D D E\n",
      "2022-01-19 14:23:12,489 - root - INFO - input_ids: 5 5 6 6 3 3 4\n",
      "2022-01-19 14:23:12,490 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,490 - root - INFO - masked_lm_positions: 2 3 4 5\n",
      "2022-01-19 14:23:12,490 - root - INFO - masked_lm_ids: 6 6 3 3\n",
      "2022-01-19 14:23:12,490 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,491 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,492 - root - INFO - tokens: E O O N N O O\n",
      "2022-01-19 14:23:12,492 - root - INFO - input_ids: 4 6 6 5 5 6 6\n",
      "2022-01-19 14:23:12,492 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,493 - root - INFO - masked_lm_positions: 0 2 4 6\n",
      "2022-01-19 14:23:12,493 - root - INFO - masked_lm_ids: 4 6 5 6\n",
      "2022-01-19 14:23:12,493 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,494 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,494 - root - INFO - tokens: D O E E E E O\n",
      "2022-01-19 14:23:12,495 - root - INFO - input_ids: 3 6 4 4 4 4 6\n",
      "2022-01-19 14:23:12,495 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,495 - root - INFO - masked_lm_positions: 0 1 5 6\n",
      "2022-01-19 14:23:12,495 - root - INFO - masked_lm_ids: 3 6 4 6\n",
      "2022-01-19 14:23:12,496 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,496 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,497 - root - INFO - tokens: D D E O O D D\n",
      "2022-01-19 14:23:12,497 - root - INFO - input_ids: 3 3 4 6 6 3 3\n",
      "2022-01-19 14:23:12,497 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,497 - root - INFO - masked_lm_positions: 3 4 5 6\n",
      "2022-01-19 14:23:12,497 - root - INFO - masked_lm_ids: 6 6 3 3\n",
      "2022-01-19 14:23:12,498 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,498 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,499 - root - INFO - tokens: N O O O O D D\n",
      "2022-01-19 14:23:12,499 - root - INFO - input_ids: 5 6 6 6 6 3 3\n",
      "2022-01-19 14:23:12,499 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,499 - root - INFO - masked_lm_positions: 0 2 4 5\n",
      "2022-01-19 14:23:12,500 - root - INFO - masked_lm_ids: 5 6 6 3\n",
      "2022-01-19 14:23:12,500 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,501 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,501 - root - INFO - tokens: O D N O O E E\n",
      "2022-01-19 14:23:12,501 - root - INFO - input_ids: 6 3 5 6 6 4 4\n",
      "2022-01-19 14:23:12,501 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,501 - root - INFO - masked_lm_positions: 1 2 4 5\n",
      "2022-01-19 14:23:12,502 - root - INFO - masked_lm_ids: 3 5 6 4\n",
      "2022-01-19 14:23:12,502 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,503 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,503 - root - INFO - tokens: E E O N N O O\n",
      "2022-01-19 14:23:12,503 - root - INFO - input_ids: 4 4 6 5 5 6 6\n",
      "2022-01-19 14:23:12,503 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,504 - root - INFO - masked_lm_positions: 1 2 4 6\n",
      "2022-01-19 14:23:12,504 - root - INFO - masked_lm_ids: 4 6 5 6\n",
      "2022-01-19 14:23:12,504 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,505 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,505 - root - INFO - tokens: O N N O O D O\n",
      "2022-01-19 14:23:12,505 - root - INFO - input_ids: 6 5 5 6 6 3 6\n",
      "2022-01-19 14:23:12,506 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,506 - root - INFO - masked_lm_positions: 0 3 4 5\n",
      "2022-01-19 14:23:12,506 - root - INFO - masked_lm_ids: 6 6 6 3\n",
      "2022-01-19 14:23:12,507 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,507 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,508 - root - INFO - tokens: N N O O O O N\n",
      "2022-01-19 14:23:12,508 - root - INFO - input_ids: 5 5 6 6 6 6 5\n",
      "2022-01-19 14:23:12,508 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,508 - root - INFO - masked_lm_positions: 0 2 3 6\n",
      "2022-01-19 14:23:12,509 - root - INFO - masked_lm_ids: 5 6 6 5\n",
      "2022-01-19 14:23:12,509 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,510 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,510 - root - INFO - tokens: O O O O O D D\n",
      "2022-01-19 14:23:12,510 - root - INFO - input_ids: 6 6 6 6 6 3 3\n",
      "2022-01-19 14:23:12,510 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,511 - root - INFO - masked_lm_positions: 0 1 2 3\n",
      "2022-01-19 14:23:12,511 - root - INFO - masked_lm_ids: 6 6 6 6\n",
      "2022-01-19 14:23:12,511 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:12,512 - root - INFO - *** Example ***\n",
      "2022-01-19 14:23:12,512 - root - INFO - tokens: O N N O O E E\n",
      "2022-01-19 14:23:12,512 - root - INFO - input_ids: 6 5 5 6 6 4 4\n",
      "2022-01-19 14:23:12,512 - root - INFO - input_mask: 1 1 1 1 1 1 1\n",
      "2022-01-19 14:23:12,513 - root - INFO - masked_lm_positions: 1 3 4 6\n",
      "2022-01-19 14:23:12,513 - root - INFO - masked_lm_ids: 5 6 6 4\n",
      "2022-01-19 14:23:12,513 - root - INFO - masked_lm_weights: 1.0 1.0 1.0 1.0\n",
      "2022-01-19 14:23:14,780 - root - INFO - Wrote 5300 total instances\n"
     ]
    }
   ],
   "source": [
    "write_instance_to_example_files(instances, tokenizer, max_seq_length, max_predictions_per_seq, [\"./test.tf_record\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Config는 적절히 수정하셔서 사용하셔야됩니다. (vocab_size같은거)\n",
    "bert_config_file = './config/bert_config.json'\n",
    "do_train = True\n",
    "do_eval = True\n",
    "input_file = './test.tf_record'\n",
    "output_dir = './model_output'\n",
    "save_checkpoints_steps = 10\n",
    "learning_rate = 5e-5\n",
    "train_batch_size = 14\n",
    "eval_batch_size = 14\n",
    "num_train_steps = 100\n",
    "num_warmup_steps= -1\n",
    "max_eval_steps=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_indexes(sequence_tensor, positions):\n",
    "    \"\"\"Gathers the vectors at the specific positions over a minibatch.\"\"\"\n",
    "    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n",
    "    batch_size = sequence_shape[0]\n",
    "    seq_length = sequence_shape[1]\n",
    "    width = sequence_shape[2]\n",
    "\n",
    "    flat_offsets = tf.reshape(\n",
    "        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n",
    "    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n",
    "    flat_sequence_tensor = tf.reshape(sequence_tensor,\n",
    "                                      [batch_size * seq_length, width])\n",
    "    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_lm_output(bert_config, input_tensor, output_weights, positions,\n",
    "                         label_ids, label_weights):\n",
    "    \"\"\"Get loss and log probs for the masked LM.\"\"\"\n",
    "    # 텐서 값의 특정 포지션을 가져온다. 여기서는 masking 처리된 값만 가져옴.\n",
    "    input_tensor = gather_indexes(input_tensor, positions)\n",
    "\n",
    "    with tf.variable_scope(\"cls/predictions\"):\n",
    "        with tf.variable_scope(\"transform\"):\n",
    "            input_tensor = tf.layers.dense(\n",
    "                input_tensor,\n",
    "                units=bert_config.hidden_size,\n",
    "                activation=modeling.get_activation(bert_config.hidden_act),\n",
    "                kernel_initializer=modeling.create_initializer(\n",
    "                    bert_config.initializer_range))\n",
    "            input_tensor = modeling.layer_norm(input_tensor)\n",
    "\n",
    "        # The output weights are the same as the input embeddings, but there is\n",
    "        # an output-only bias for each token.\n",
    "        output_bias = tf.get_variable(\n",
    "            \"output_bias\",\n",
    "            shape=[bert_config.vocab_size],\n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        label_ids = tf.reshape(label_ids, [-1])\n",
    "        label_weights = tf.reshape(label_weights, [-1])\n",
    "\n",
    "        one_hot_labels = tf.one_hot(\n",
    "            label_ids, depth=bert_config.vocab_size, dtype=tf.float32)\n",
    "\n",
    "        per_example_loss = - \\\n",
    "            tf.reduce_sum(log_probs * one_hot_labels, axis=[-1])\n",
    "        numerator = tf.reduce_sum(label_weights * per_example_loss)\n",
    "        denominator = tf.reduce_sum(label_weights) + 1e-5\n",
    "        loss = numerator / denominator\n",
    "\n",
    "    return (loss, per_example_loss, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     use_one_hot_embeddings):\n",
    "\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            logging.info(\"  name = %s, shape = %s\" %\n",
    "                            (name, features[name].shape))\n",
    "\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        masked_lm_positions = features[\"masked_lm_positions\"]\n",
    "        masked_lm_ids = features[\"masked_lm_ids\"]\n",
    "        masked_lm_weights = features[\"masked_lm_weights\"]\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "        model = modeling.BertModel(\n",
    "            config=bert_config,\n",
    "            is_training=is_training,\n",
    "            input_ids=input_ids,\n",
    "            input_mask=input_mask,\n",
    "            use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "\n",
    "        (masked_lm_loss,\n",
    "         masked_lm_example_loss, masked_lm_log_probs) = get_masked_lm_output(\n",
    "             bert_config, model.get_sequence_output(), model.get_embedding_table(),\n",
    "             masked_lm_positions, masked_lm_ids, masked_lm_weights)\n",
    "\n",
    "        # 2개의 예측에 대한 토탈 로스\n",
    "        total_loss = masked_lm_loss\n",
    "\n",
    "        tvars = tf.trainable_variables()\n",
    "\n",
    "        initialized_variable_names = {}\n",
    "        scaffold_fn = None\n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names\n",
    "             ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "            if use_tpu:\n",
    "\n",
    "                def tpu_scaffold():\n",
    "                    tf.train.init_from_checkpoint(\n",
    "                        init_checkpoint, assignment_map)\n",
    "                    return tf.train.Scaffold()\n",
    "\n",
    "                scaffold_fn = tpu_scaffold\n",
    "            else:\n",
    "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "        tf.logging.info(\"**** Trainable Variables ****\")\n",
    "        for var in tvars:\n",
    "            init_string = \"\"\n",
    "            if var.name in initialized_variable_names:\n",
    "                init_string = \", *INIT_FROM_CKPT*\"\n",
    "            logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "                            init_string)\n",
    "\n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # 토탈 로스를 최소화 하기위한 옵티마이저\n",
    "            train_op = optimization.create_optimizer(\n",
    "                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "\n",
    "            output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                train_op=train_op,\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "            # 검증에서는 비교적 상세 정보를 출력해주도록 함.\n",
    "            def metric_fn(masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
    "                          masked_lm_weights):\n",
    "                \"\"\"Computes the loss and accuracy of the model.\"\"\"\n",
    "                masked_lm_log_probs = tf.reshape(masked_lm_log_probs,\n",
    "                                                 [-1, masked_lm_log_probs.shape[-1]])\n",
    "                masked_lm_predictions = tf.argmax(\n",
    "                    masked_lm_log_probs, axis=-1, output_type=tf.int32)\n",
    "                masked_lm_example_loss = tf.reshape(\n",
    "                    masked_lm_example_loss, [-1])\n",
    "                masked_lm_ids = tf.reshape(masked_lm_ids, [-1])\n",
    "                masked_lm_weights = tf.reshape(masked_lm_weights, [-1])\n",
    "                masked_lm_accuracy = tf.metrics.accuracy(\n",
    "                    labels=masked_lm_ids,\n",
    "                    predictions=masked_lm_predictions,\n",
    "                    weights=masked_lm_weights)\n",
    "                masked_lm_mean_loss = tf.metrics.mean(\n",
    "                    values=masked_lm_example_loss, weights=masked_lm_weights)\n",
    "\n",
    "                return {\n",
    "                    \"masked_lm_accuracy\": masked_lm_accuracy,\n",
    "                    \"masked_lm_loss\": masked_lm_mean_loss\n",
    "                }\n",
    "\n",
    "            eval_metrics = (metric_fn, [\n",
    "                masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
    "                masked_lm_weights\n",
    "            ])\n",
    "            output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                eval_metrics=eval_metrics,\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Only TRAIN and EVAL modes are supported: %s\" % (mode))\n",
    "\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.cast(t,tf.int32)\n",
    "        example[name] = t\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(input_files,\n",
    "                     max_seq_length,\n",
    "                     max_predictions_per_seq,\n",
    "                     is_training,\n",
    "                     num_cpu_threads=4):\n",
    "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "    \n",
    "    def input_fn(params):\n",
    "        \"\"\"The actual input function.\"\"\"\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        name_to_features = {\n",
    "            \"input_ids\":\n",
    "                tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "            # NSP를 하지 않으므로, 값이 살짝 다릅니다 참고하세요\n",
    "            \"input_mask\":\n",
    "                tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "            \"masked_lm_positions\":\n",
    "                tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "            \"masked_lm_ids\":\n",
    "                tf.io.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "            \"masked_lm_weights\":\n",
    "                tf.io.FixedLenFeature([max_predictions_per_seq], tf.float32)\n",
    "        }\n",
    "\n",
    "        # For training, we want a lot of parallel reading and shuffling.\n",
    "        # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "        if is_training:\n",
    "            d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=len(input_files))\n",
    "\n",
    "            # `cycle_length` is the number of parallel files that get read.\n",
    "            cycle_length = min(num_cpu_threads, len(input_files))\n",
    "\n",
    "            # `sloppy` mode means that the interleaving is not exact. This adds\n",
    "            # even more randomness to the training pipeline.\n",
    "            d = d.apply(\n",
    "                tf.data.experimental.parallel_interleave(\n",
    "                    tf.data.TFRecordDataset,\n",
    "                    sloppy=is_training,\n",
    "                    cycle_length=cycle_length))\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "        else:\n",
    "            d = tf.data.TFRecordDataset(input_files)\n",
    "            # Since we evaluate for a fixed number of steps we don't want to encounter\n",
    "            # out-of-range exceptions.\n",
    "            d = d.repeat()\n",
    "\n",
    "        # We must `drop_remainder` on training because the TPU requires fixed\n",
    "        # size dimensions. For eval, we assume we are evaluating on the CPU or GPU\n",
    "        # and we *don't* want to drop the remainder, otherwise we wont cover\n",
    "        # every sample.\n",
    "        d = d.apply(\n",
    "            tf.data.experimental.map_and_batch(\n",
    "                lambda record: _decode_record(record, name_to_features),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_batches=num_cpu_threads,\n",
    "                drop_remainder=True))\n",
    "        return d\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Input Files ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,822 - tensorflow - INFO - *** Input Files ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_file_name:  .\\test.tf_record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,823 - tensorflow - INFO - input_file_name:  .\\test.tf_record\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x000001AE5EB2BDC0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,885 - tensorflow - WARNING - Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x000001AE5EB2BDC0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './model_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,886 - tensorflow - INFO - Using config: {'_model_dir': './model_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,887 - tensorflow - INFO - _TPUContext: eval_on_tpu True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,887 - tensorflow - WARNING - eval_on_tpu ignored because use_tpu is False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,888 - tensorflow - INFO - ***** Running training *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Batch size = 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,889 - tensorflow - INFO -   Batch size = 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,894 - tensorflow - WARNING - From C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-202dbabf6790>:38: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,903 - tensorflow - WARNING - From <ipython-input-15-202dbabf6790>:38: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-202dbabf6790>:54: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,923 - tensorflow - WARNING - From <ipython-input-15-202dbabf6790>:54: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,995 - tensorflow - INFO - Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running train on CPU/GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:16,995 - tensorflow - INFO - Running train on CPU/GPU\n",
      "2022-01-19 14:23:16,996 - root - INFO - *** Features ***\n",
      "2022-01-19 14:23:16,997 - root - INFO -   name = input_ids, shape = (14, 7)\n",
      "2022-01-19 14:23:16,997 - root - INFO -   name = input_mask, shape = (14, 7)\n",
      "2022-01-19 14:23:16,997 - root - INFO -   name = masked_lm_ids, shape = (14, 4)\n",
      "2022-01-19 14:23:16,998 - root - INFO -   name = masked_lm_positions, shape = (14, 4)\n",
      "2022-01-19 14:23:16,998 - root - INFO -   name = masked_lm_weights, shape = (14, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:17,027 - tensorflow - WARNING - From C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bert/pooler/dense/Tanh:0\", shape=(14, 768), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:18,332 - tensorflow - INFO - **** Trainable Variables ****\n",
      "2022-01-19 14:23:18,333 - root - INFO -   name = bert/embeddings/word_embeddings:0, shape = (7, 768)\n",
      "2022-01-19 14:23:18,334 - root - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,334 - root - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,334 - root - INFO -   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,334 - root - INFO -   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,335 - root - INFO -   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,335 - root - INFO -   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,335 - root - INFO -   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,335 - root - INFO -   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,336 - root - INFO -   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,336 - root - INFO -   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,336 - root - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,336 - root - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,337 - root - INFO -   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,337 - root - INFO -   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,337 - root - INFO -   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,337 - root - INFO -   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,338 - root - INFO -   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,338 - root - INFO -   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,338 - root - INFO -   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,338 - root - INFO -   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,339 - root - INFO -   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,339 - root - INFO -   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,339 - root - INFO -   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,339 - root - INFO -   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,340 - root - INFO -   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,340 - root - INFO -   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,340 - root - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,341 - root - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,341 - root - INFO -   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,341 - root - INFO -   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,341 - root - INFO -   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,342 - root - INFO -   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,342 - root - INFO -   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,342 - root - INFO -   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,343 - root - INFO -   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,343 - root - INFO -   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,343 - root - INFO -   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,344 - root - INFO -   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,344 - root - INFO -   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,344 - root - INFO -   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,345 - root - INFO -   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,345 - root - INFO -   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,345 - root - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,345 - root - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,346 - root - INFO -   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,346 - root - INFO -   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,346 - root - INFO -   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,346 - root - INFO -   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,347 - root - INFO -   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,347 - root - INFO -   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,347 - root - INFO -   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,348 - root - INFO -   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,348 - root - INFO -   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,348 - root - INFO -   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,348 - root - INFO -   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,349 - root - INFO -   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,349 - root - INFO -   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,349 - root - INFO -   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,349 - root - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,350 - root - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,350 - root - INFO -   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,350 - root - INFO -   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,350 - root - INFO -   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,351 - root - INFO -   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,351 - root - INFO -   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,351 - root - INFO -   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,351 - root - INFO -   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,352 - root - INFO -   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,352 - root - INFO -   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,352 - root - INFO -   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,352 - root - INFO -   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,353 - root - INFO -   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,353 - root - INFO -   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,353 - root - INFO -   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,353 - root - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,354 - root - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,354 - root - INFO -   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,354 - root - INFO -   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,354 - root - INFO -   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,355 - root - INFO -   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,355 - root - INFO -   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,355 - root - INFO -   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,355 - root - INFO -   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,356 - root - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,356 - root - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,356 - root - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,356 - root - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,357 - root - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,357 - root - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,357 - root - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,357 - root - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,358 - root - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,358 - root - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,358 - root - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,359 - root - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,359 - root - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,359 - root - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,360 - root - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,360 - root - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,360 - root - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,360 - root - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,360 - root - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,361 - root - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,361 - root - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,361 - root - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,362 - root - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,362 - root - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,362 - root - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,362 - root - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,363 - root - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,363 - root - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,363 - root - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,363 - root - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,364 - root - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,364 - root - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,364 - root - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,364 - root - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,365 - root - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,365 - root - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,365 - root - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,365 - root - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,366 - root - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,366 - root - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,366 - root - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,366 - root - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,367 - root - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,367 - root - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,367 - root - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,367 - root - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,368 - root - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,368 - root - INFO -   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,368 - root - INFO -   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,368 - root - INFO -   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,369 - root - INFO -   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,369 - root - INFO -   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,369 - root - INFO -   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,369 - root - INFO -   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,370 - root - INFO -   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,370 - root - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,370 - root - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,370 - root - INFO -   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,371 - root - INFO -   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,371 - root - INFO -   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,371 - root - INFO -   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,371 - root - INFO -   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,372 - root - INFO -   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,372 - root - INFO -   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,373 - root - INFO -   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,373 - root - INFO -   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,373 - root - INFO -   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,374 - root - INFO -   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,374 - root - INFO -   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,374 - root - INFO -   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,374 - root - INFO -   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,375 - root - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,375 - root - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,375 - root - INFO -   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,375 - root - INFO -   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,376 - root - INFO -   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,376 - root - INFO -   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,376 - root - INFO -   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,376 - root - INFO -   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,376 - root - INFO -   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,377 - root - INFO -   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,377 - root - INFO -   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,377 - root - INFO -   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,377 - root - INFO -   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,378 - root - INFO -   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,378 - root - INFO -   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,378 - root - INFO -   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,378 - root - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,379 - root - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,379 - root - INFO -   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,379 - root - INFO -   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,379 - root - INFO -   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,380 - root - INFO -   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,380 - root - INFO -   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,380 - root - INFO -   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,380 - root - INFO -   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,381 - root - INFO -   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,381 - root - INFO -   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,381 - root - INFO -   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,381 - root - INFO -   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,382 - root - INFO -   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,382 - root - INFO -   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,382 - root - INFO -   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,382 - root - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,383 - root - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,383 - root - INFO -   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:23:18,383 - root - INFO -   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:23:18,383 - root - INFO -   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:23:18,384 - root - INFO -   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,384 - root - INFO -   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,384 - root - INFO -   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,384 - root - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,385 - root - INFO -   name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,386 - root - INFO -   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:23:18,386 - root - INFO -   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:23:18,386 - root - INFO -   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:23:18,386 - root - INFO -   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:23:18,387 - root - INFO -   name = cls/predictions/output_bias:0, shape = (7,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:21,708 - tensorflow - INFO - Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:21,710 - tensorflow - INFO - Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:30,741 - tensorflow - INFO - Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:33,728 - tensorflow - INFO - Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:33,851 - tensorflow - INFO - Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:47,717 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:47,723 - tensorflow - INFO - Saving checkpoints for 0 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:23:56,098 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.577778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,273 - tensorflow - INFO - global_step/sec: 0.577778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 8.08889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,274 - tensorflow - INFO - examples/sec: 8.08889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.42564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,429 - tensorflow - INFO - global_step/sec: 6.42564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 89.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,431 - tensorflow - INFO - examples/sec: 89.959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.86942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,574 - tensorflow - INFO - global_step/sec: 6.86942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 96.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,575 - tensorflow - INFO - examples/sec: 96.1719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.59792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,706 - tensorflow - INFO - global_step/sec: 7.59792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 106.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,707 - tensorflow - INFO - examples/sec: 106.371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.81655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,834 - tensorflow - INFO - global_step/sec: 7.81655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 109.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,836 - tensorflow - INFO - examples/sec: 109.432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.74161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,963 - tensorflow - INFO - global_step/sec: 7.74161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:01,964 - tensorflow - INFO - examples/sec: 108.383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.73534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:02,092 - tensorflow - INFO - global_step/sec: 7.73534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:02,093 - tensorflow - INFO - examples/sec: 108.295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.8603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:02,220 - tensorflow - INFO - global_step/sec: 7.8603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:02,221 - tensorflow - INFO - examples/sec: 110.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:02,347 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:02,348 - tensorflow - INFO - Saving checkpoints for 10 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:08,888 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.149923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:08,890 - tensorflow - INFO - global_step/sec: 0.149923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 2.09893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:08,891 - tensorflow - INFO - examples/sec: 2.09893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.84714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,241 - tensorflow - INFO - global_step/sec: 2.84714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 39.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,242 - tensorflow - INFO - examples/sec: 39.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.95774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,367 - tensorflow - INFO - global_step/sec: 7.95774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,368 - tensorflow - INFO - examples/sec: 111.408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.30799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,504 - tensorflow - INFO - global_step/sec: 7.30799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 102.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,505 - tensorflow - INFO - examples/sec: 102.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.71098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,633 - tensorflow - INFO - global_step/sec: 7.71098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,634 - tensorflow - INFO - examples/sec: 107.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.88339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,760 - tensorflow - INFO - global_step/sec: 7.88339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,762 - tensorflow - INFO - examples/sec: 110.368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.01307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,885 - tensorflow - INFO - global_step/sec: 8.01307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:09,886 - tensorflow - INFO - examples/sec: 112.183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.18155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,007 - tensorflow - INFO - global_step/sec: 8.18155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 114.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,009 - tensorflow - INFO - examples/sec: 114.542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,131 - tensorflow - INFO - global_step/sec: 8.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 114.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,132 - tensorflow - INFO - examples/sec: 114.16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.96509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,255 - tensorflow - INFO - global_step/sec: 7.96509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,257 - tensorflow - INFO - examples/sec: 111.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,381 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 20...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 20 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:10,381 - tensorflow - INFO - Saving checkpoints for 20 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:17,443 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 20...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.139098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:17,445 - tensorflow - INFO - global_step/sec: 0.139098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 1.94738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:17,445 - tensorflow - INFO - examples/sec: 1.94738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.74873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:17,808 - tensorflow - INFO - global_step/sec: 2.74873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 38.4822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:17,809 - tensorflow - INFO - examples/sec: 38.4822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.94526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:17,934 - tensorflow - INFO - global_step/sec: 7.94526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:17,935 - tensorflow - INFO - examples/sec: 111.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.37845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,069 - tensorflow - INFO - global_step/sec: 7.37845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 103.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,070 - tensorflow - INFO - examples/sec: 103.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.47504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,203 - tensorflow - INFO - global_step/sec: 7.47504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 104.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,205 - tensorflow - INFO - examples/sec: 104.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.65397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,334 - tensorflow - INFO - global_step/sec: 7.65397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,335 - tensorflow - INFO - examples/sec: 107.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.58413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,466 - tensorflow - INFO - global_step/sec: 7.58413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 106.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,468 - tensorflow - INFO - examples/sec: 106.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.64835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,597 - tensorflow - INFO - global_step/sec: 7.64835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,598 - tensorflow - INFO - examples/sec: 107.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.59415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,728 - tensorflow - INFO - global_step/sec: 7.59415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 106.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,729 - tensorflow - INFO - examples/sec: 106.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.7457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,857 - tensorflow - INFO - global_step/sec: 7.7457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,858 - tensorflow - INFO - examples/sec: 108.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,985 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 30...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 30 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:18,986 - tensorflow - INFO - Saving checkpoints for 30 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:25,717 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 30...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.145721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:25,720 - tensorflow - INFO - global_step/sec: 0.145721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 2.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:25,721 - tensorflow - INFO - examples/sec: 2.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.23443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,029 - tensorflow - INFO - global_step/sec: 3.23443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 45.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,030 - tensorflow - INFO - examples/sec: 45.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.08608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,154 - tensorflow - INFO - global_step/sec: 8.08608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 113.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,155 - tensorflow - INFO - examples/sec: 113.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.01656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,277 - tensorflow - INFO - global_step/sec: 8.01656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,278 - tensorflow - INFO - examples/sec: 112.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.73636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,407 - tensorflow - INFO - global_step/sec: 7.73636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,408 - tensorflow - INFO - examples/sec: 108.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.05358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,531 - tensorflow - INFO - global_step/sec: 8.05358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,532 - tensorflow - INFO - examples/sec: 112.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.06276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,656 - tensorflow - INFO - global_step/sec: 8.06276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,657 - tensorflow - INFO - examples/sec: 112.879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.10777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,779 - tensorflow - INFO - global_step/sec: 8.10777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 113.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,780 - tensorflow - INFO - examples/sec: 113.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.10551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,902 - tensorflow - INFO - global_step/sec: 8.10551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 113.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:26,903 - tensorflow - INFO - examples/sec: 113.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.89653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:27,028 - tensorflow - INFO - global_step/sec: 7.89653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:27,029 - tensorflow - INFO - examples/sec: 110.551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:27,152 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 40...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 40 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:27,153 - tensorflow - INFO - Saving checkpoints for 40 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,152 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 40...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.140356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,154 - tensorflow - INFO - global_step/sec: 0.140356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 1.96498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,154 - tensorflow - INFO - examples/sec: 1.96498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.6081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,430 - tensorflow - INFO - global_step/sec: 3.6081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 50.5134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,431 - tensorflow - INFO - examples/sec: 50.5134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.65173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,561 - tensorflow - INFO - global_step/sec: 7.65173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,562 - tensorflow - INFO - examples/sec: 107.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.95127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,686 - tensorflow - INFO - global_step/sec: 7.95127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,688 - tensorflow - INFO - examples/sec: 111.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.54006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,820 - tensorflow - INFO - global_step/sec: 7.54006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 105.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,821 - tensorflow - INFO - examples/sec: 105.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.71291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,949 - tensorflow - INFO - global_step/sec: 7.71291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:34,950 - tensorflow - INFO - examples/sec: 107.981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.94745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,075 - tensorflow - INFO - global_step/sec: 7.94745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,077 - tensorflow - INFO - examples/sec: 111.264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.95771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,200 - tensorflow - INFO - global_step/sec: 7.95771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,201 - tensorflow - INFO - examples/sec: 111.408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.01262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,326 - tensorflow - INFO - global_step/sec: 8.01262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,327 - tensorflow - INFO - examples/sec: 112.177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.97296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,450 - tensorflow - INFO - global_step/sec: 7.97296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,452 - tensorflow - INFO - examples/sec: 111.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,576 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 50...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 50 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:35,577 - tensorflow - INFO - Saving checkpoints for 50 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\saver.py:968: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:36,969 - tensorflow - WARNING - From C:\\Users\\shyu\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\saver.py:968: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,293 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 50...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.146094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,295 - tensorflow - INFO - global_step/sec: 0.146094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 2.04531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,296 - tensorflow - INFO - examples/sec: 2.04531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.31279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,597 - tensorflow - INFO - global_step/sec: 3.31279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 46.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,598 - tensorflow - INFO - examples/sec: 46.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.47291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,732 - tensorflow - INFO - global_step/sec: 7.47291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 104.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,733 - tensorflow - INFO - examples/sec: 104.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.22487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,869 - tensorflow - INFO - global_step/sec: 7.22487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 101.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:42,871 - tensorflow - INFO - examples/sec: 101.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.13993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,010 - tensorflow - INFO - global_step/sec: 7.13993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 99.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,011 - tensorflow - INFO - examples/sec: 99.9591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.85747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,137 - tensorflow - INFO - global_step/sec: 7.85747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,138 - tensorflow - INFO - examples/sec: 110.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.65437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,267 - tensorflow - INFO - global_step/sec: 7.65437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,268 - tensorflow - INFO - examples/sec: 107.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.5969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,399 - tensorflow - INFO - global_step/sec: 7.5969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 106.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,400 - tensorflow - INFO - examples/sec: 106.357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.95444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,525 - tensorflow - INFO - global_step/sec: 7.95444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,526 - tensorflow - INFO - examples/sec: 111.362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.02142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,650 - tensorflow - INFO - global_step/sec: 8.02142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,651 - tensorflow - INFO - examples/sec: 112.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,775 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 60...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 60 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:43,776 - tensorflow - INFO - Saving checkpoints for 60 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:51,422 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 60...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.128628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:51,424 - tensorflow - INFO - global_step/sec: 0.128628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 1.80079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:51,425 - tensorflow - INFO - examples/sec: 1.80079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.75631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:51,787 - tensorflow - INFO - global_step/sec: 2.75631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 38.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:51,788 - tensorflow - INFO - examples/sec: 38.5883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.89466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:51,913 - tensorflow - INFO - global_step/sec: 7.89466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:51,914 - tensorflow - INFO - examples/sec: 110.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.30065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,050 - tensorflow - INFO - global_step/sec: 7.30065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 102.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,051 - tensorflow - INFO - examples/sec: 102.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.54434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,183 - tensorflow - INFO - global_step/sec: 7.54434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 105.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,184 - tensorflow - INFO - examples/sec: 105.621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.90877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,309 - tensorflow - INFO - global_step/sec: 7.90877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,310 - tensorflow - INFO - examples/sec: 110.723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.65399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,440 - tensorflow - INFO - global_step/sec: 7.65399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,441 - tensorflow - INFO - examples/sec: 107.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.95779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,567 - tensorflow - INFO - global_step/sec: 7.95779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,567 - tensorflow - INFO - examples/sec: 111.409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.67506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,696 - tensorflow - INFO - global_step/sec: 7.67506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,697 - tensorflow - INFO - examples/sec: 107.451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.77845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,824 - tensorflow - INFO - global_step/sec: 7.77845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,825 - tensorflow - INFO - examples/sec: 108.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 70...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,949 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 70...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 70 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:52,951 - tensorflow - INFO - Saving checkpoints for 70 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 70...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:59,950 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 70...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.140294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:59,952 - tensorflow - INFO - global_step/sec: 0.140294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 1.96411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:24:59,953 - tensorflow - INFO - examples/sec: 1.96411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.34078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,380 - tensorflow - INFO - global_step/sec: 2.34078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 32.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,381 - tensorflow - INFO - examples/sec: 32.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.47625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,513 - tensorflow - INFO - global_step/sec: 7.47625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 104.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,514 - tensorflow - INFO - examples/sec: 104.668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.34021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,650 - tensorflow - INFO - global_step/sec: 7.34021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 102.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,652 - tensorflow - INFO - examples/sec: 102.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.79426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,778 - tensorflow - INFO - global_step/sec: 7.79426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 109.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,779 - tensorflow - INFO - examples/sec: 109.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.55769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,910 - tensorflow - INFO - global_step/sec: 7.55769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 105.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:00,912 - tensorflow - INFO - examples/sec: 105.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.71288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,040 - tensorflow - INFO - global_step/sec: 7.71288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,041 - tensorflow - INFO - examples/sec: 107.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.65708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,170 - tensorflow - INFO - global_step/sec: 7.65708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,171 - tensorflow - INFO - examples/sec: 107.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.68242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,301 - tensorflow - INFO - global_step/sec: 7.68242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 107.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,303 - tensorflow - INFO - examples/sec: 107.554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.71798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,430 - tensorflow - INFO - global_step/sec: 7.71798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,431 - tensorflow - INFO - examples/sec: 108.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 80...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,559 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 80...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 80 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:01,560 - tensorflow - INFO - Saving checkpoints for 80 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 80...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:08,462 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 80...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.142169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:08,464 - tensorflow - INFO - global_step/sec: 0.142169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 1.99037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:08,465 - tensorflow - INFO - examples/sec: 1.99037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.09263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:08,787 - tensorflow - INFO - global_step/sec: 3.09263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 43.2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:08,788 - tensorflow - INFO - examples/sec: 43.2968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:08,920 - tensorflow - INFO - global_step/sec: 7.558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 105.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:08,921 - tensorflow - INFO - examples/sec: 105.812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.77268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,048 - tensorflow - INFO - global_step/sec: 7.77268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,049 - tensorflow - INFO - examples/sec: 108.818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,180 - tensorflow - INFO - global_step/sec: 7.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 106.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,181 - tensorflow - INFO - examples/sec: 106.246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.88842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,308 - tensorflow - INFO - global_step/sec: 7.88842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,309 - tensorflow - INFO - examples/sec: 110.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.83456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,434 - tensorflow - INFO - global_step/sec: 7.83456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 109.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,435 - tensorflow - INFO - examples/sec: 109.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.02137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,559 - tensorflow - INFO - global_step/sec: 8.02137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,560 - tensorflow - INFO - examples/sec: 112.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.74423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,688 - tensorflow - INFO - global_step/sec: 7.74423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,689 - tensorflow - INFO - examples/sec: 108.419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.01131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,813 - tensorflow - INFO - global_step/sec: 8.01131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 112.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,815 - tensorflow - INFO - examples/sec: 112.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 90...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,944 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 90...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 90 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:09,945 - tensorflow - INFO - Saving checkpoints for 90 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 90...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,094 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 90...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.137334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,096 - tensorflow - INFO - global_step/sec: 0.137334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 1.92268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,096 - tensorflow - INFO - examples/sec: 1.92268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.13684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,413 - tensorflow - INFO - global_step/sec: 3.13684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 43.9158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,414 - tensorflow - INFO - examples/sec: 43.9158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.86093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,541 - tensorflow - INFO - global_step/sec: 7.86093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 110.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,542 - tensorflow - INFO - examples/sec: 110.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.76911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,670 - tensorflow - INFO - global_step/sec: 7.76911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,671 - tensorflow - INFO - examples/sec: 108.768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.48953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,804 - tensorflow - INFO - global_step/sec: 7.48953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 104.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,805 - tensorflow - INFO - examples/sec: 104.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.82366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,931 - tensorflow - INFO - global_step/sec: 7.82366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 109.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:17,932 - tensorflow - INFO - examples/sec: 109.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.95645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,057 - tensorflow - INFO - global_step/sec: 7.95645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 111.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,058 - tensorflow - INFO - examples/sec: 111.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.77263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,185 - tensorflow - INFO - global_step/sec: 7.77263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 108.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,186 - tensorflow - INFO - examples/sec: 108.817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.84715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,312 - tensorflow - INFO - global_step/sec: 7.84715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 109.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,313 - tensorflow - INFO - examples/sec: 109.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.79167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,442 - tensorflow - INFO - global_step/sec: 7.79167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 109.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,443 - tensorflow - INFO - examples/sec: 109.083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,568 - tensorflow - INFO - Calling checkpoint listeners before saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:18,570 - tensorflow - INFO - Saving checkpoints for 100 into ./model_output\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,497 - tensorflow - INFO - Calling checkpoint listeners after saving checkpoint 100...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.141655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,500 - tensorflow - INFO - global_step/sec: 0.141655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:examples/sec: 1.98317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,501 - tensorflow - INFO - examples/sec: 1.98317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.007437828.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,587 - tensorflow - INFO - Loss for final step: 0.007437828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,588 - tensorflow - INFO - training_loop marked as finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,589 - tensorflow - INFO - ***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  Batch size = 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,590 - tensorflow - INFO -   Batch size = 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,619 - tensorflow - INFO - Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running eval on CPU/GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:25,620 - tensorflow - INFO - Running eval on CPU/GPU\n",
      "2022-01-19 14:25:25,621 - root - INFO - *** Features ***\n",
      "2022-01-19 14:25:25,621 - root - INFO -   name = input_ids, shape = (14, 7)\n",
      "2022-01-19 14:25:25,622 - root - INFO -   name = input_mask, shape = (14, 7)\n",
      "2022-01-19 14:25:25,622 - root - INFO -   name = masked_lm_ids, shape = (14, 4)\n",
      "2022-01-19 14:25:25,623 - root - INFO -   name = masked_lm_positions, shape = (14, 4)\n",
      "2022-01-19 14:25:25,623 - root - INFO -   name = masked_lm_weights, shape = (14, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bert/pooler/dense/Tanh:0\", shape=(14, 768), dtype=float32)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:26,882 - tensorflow - INFO - **** Trainable Variables ****\n",
      "2022-01-19 14:25:26,883 - root - INFO -   name = bert/embeddings/word_embeddings:0, shape = (7, 768)\n",
      "2022-01-19 14:25:26,884 - root - INFO -   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,884 - root - INFO -   name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,884 - root - INFO -   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,885 - root - INFO -   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,885 - root - INFO -   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,885 - root - INFO -   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,886 - root - INFO -   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,886 - root - INFO -   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,886 - root - INFO -   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,887 - root - INFO -   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,887 - root - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,888 - root - INFO -   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,888 - root - INFO -   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,888 - root - INFO -   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,889 - root - INFO -   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,889 - root - INFO -   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,889 - root - INFO -   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,889 - root - INFO -   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,890 - root - INFO -   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,890 - root - INFO -   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,890 - root - INFO -   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,891 - root - INFO -   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,891 - root - INFO -   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,891 - root - INFO -   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,891 - root - INFO -   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,892 - root - INFO -   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,892 - root - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,892 - root - INFO -   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,893 - root - INFO -   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,893 - root - INFO -   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,893 - root - INFO -   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,893 - root - INFO -   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,894 - root - INFO -   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,894 - root - INFO -   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,894 - root - INFO -   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,894 - root - INFO -   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,894 - root - INFO -   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,895 - root - INFO -   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,895 - root - INFO -   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,895 - root - INFO -   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,895 - root - INFO -   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,896 - root - INFO -   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,896 - root - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,896 - root - INFO -   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,896 - root - INFO -   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,897 - root - INFO -   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,897 - root - INFO -   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,897 - root - INFO -   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,898 - root - INFO -   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,898 - root - INFO -   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,898 - root - INFO -   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,898 - root - INFO -   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,899 - root - INFO -   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,899 - root - INFO -   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,899 - root - INFO -   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,899 - root - INFO -   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,900 - root - INFO -   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,900 - root - INFO -   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,900 - root - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,900 - root - INFO -   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,901 - root - INFO -   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,901 - root - INFO -   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,901 - root - INFO -   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,901 - root - INFO -   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,902 - root - INFO -   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,902 - root - INFO -   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,902 - root - INFO -   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,902 - root - INFO -   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,903 - root - INFO -   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,903 - root - INFO -   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,903 - root - INFO -   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,903 - root - INFO -   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,904 - root - INFO -   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,904 - root - INFO -   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,904 - root - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,904 - root - INFO -   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,905 - root - INFO -   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,905 - root - INFO -   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,905 - root - INFO -   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,905 - root - INFO -   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,906 - root - INFO -   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,906 - root - INFO -   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,906 - root - INFO -   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,906 - root - INFO -   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,907 - root - INFO -   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,907 - root - INFO -   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,907 - root - INFO -   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,908 - root - INFO -   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,908 - root - INFO -   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,908 - root - INFO -   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,909 - root - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,909 - root - INFO -   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,909 - root - INFO -   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,909 - root - INFO -   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,910 - root - INFO -   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,910 - root - INFO -   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,910 - root - INFO -   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,910 - root - INFO -   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,911 - root - INFO -   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,911 - root - INFO -   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,911 - root - INFO -   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,911 - root - INFO -   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,912 - root - INFO -   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,912 - root - INFO -   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,912 - root - INFO -   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,912 - root - INFO -   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,912 - root - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,913 - root - INFO -   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,913 - root - INFO -   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,913 - root - INFO -   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,913 - root - INFO -   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,914 - root - INFO -   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,914 - root - INFO -   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,914 - root - INFO -   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,914 - root - INFO -   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,915 - root - INFO -   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,915 - root - INFO -   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,915 - root - INFO -   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,915 - root - INFO -   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,916 - root - INFO -   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,916 - root - INFO -   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,916 - root - INFO -   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,916 - root - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,917 - root - INFO -   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,917 - root - INFO -   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,917 - root - INFO -   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,918 - root - INFO -   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,918 - root - INFO -   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,918 - root - INFO -   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,918 - root - INFO -   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,918 - root - INFO -   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,919 - root - INFO -   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,919 - root - INFO -   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,919 - root - INFO -   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,920 - root - INFO -   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,920 - root - INFO -   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,920 - root - INFO -   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,920 - root - INFO -   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,920 - root - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,921 - root - INFO -   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,921 - root - INFO -   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,921 - root - INFO -   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,921 - root - INFO -   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,922 - root - INFO -   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,922 - root - INFO -   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,922 - root - INFO -   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,922 - root - INFO -   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,923 - root - INFO -   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,923 - root - INFO -   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,923 - root - INFO -   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,923 - root - INFO -   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,924 - root - INFO -   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,924 - root - INFO -   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,924 - root - INFO -   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,924 - root - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,925 - root - INFO -   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,925 - root - INFO -   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,925 - root - INFO -   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,925 - root - INFO -   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,926 - root - INFO -   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,926 - root - INFO -   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,926 - root - INFO -   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,927 - root - INFO -   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,927 - root - INFO -   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,927 - root - INFO -   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,927 - root - INFO -   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,928 - root - INFO -   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,928 - root - INFO -   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,928 - root - INFO -   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,928 - root - INFO -   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,929 - root - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,929 - root - INFO -   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,930 - root - INFO -   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,930 - root - INFO -   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,930 - root - INFO -   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,930 - root - INFO -   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,931 - root - INFO -   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,931 - root - INFO -   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,931 - root - INFO -   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,932 - root - INFO -   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,932 - root - INFO -   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,932 - root - INFO -   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,932 - root - INFO -   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,933 - root - INFO -   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,933 - root - INFO -   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,933 - root - INFO -   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,933 - root - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,934 - root - INFO -   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,934 - root - INFO -   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "2022-01-19 14:25:26,934 - root - INFO -   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "2022-01-19 14:25:26,934 - root - INFO -   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "2022-01-19 14:25:26,935 - root - INFO -   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,935 - root - INFO -   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,935 - root - INFO -   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,935 - root - INFO -   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,936 - root - INFO -   name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,936 - root - INFO -   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
      "2022-01-19 14:25:26,936 - root - INFO -   name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
      "2022-01-19 14:25:26,936 - root - INFO -   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
      "2022-01-19 14:25:26,937 - root - INFO -   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
      "2022-01-19 14:25:26,937 - root - INFO -   name = cls/predictions/output_bias:0, shape = (7,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:26,963 - tensorflow - INFO - Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2022-01-19T14:25:26Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:26,979 - tensorflow - INFO - Starting evaluation at 2022-01-19T14:25:26Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:27,255 - tensorflow - INFO - Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_output\\model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:27,258 - tensorflow - INFO - Restoring parameters from ./model_output\\model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:27,854 - tensorflow - INFO - Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:27,877 - tensorflow - INFO - Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,297 - tensorflow - INFO - Evaluation [2/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,387 - tensorflow - INFO - Evaluation [4/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,476 - tensorflow - INFO - Evaluation [6/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,511 - tensorflow - INFO - Evaluation [8/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,537 - tensorflow - INFO - Evaluation [10/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [12/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,564 - tensorflow - INFO - Evaluation [12/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [14/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,589 - tensorflow - INFO - Evaluation [14/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [16/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,614 - tensorflow - INFO - Evaluation [16/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,639 - tensorflow - INFO - Evaluation [18/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,665 - tensorflow - INFO - Evaluation [20/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 1.71835s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,698 - tensorflow - INFO - Inference Time : 1.71835s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2022-01-19-14:25:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,699 - tensorflow - INFO - Finished evaluation at 2022-01-19-14:25:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 100: global_step = 100, loss = 0.0029329616, masked_lm_accuracy = 1.0, masked_lm_loss = 0.002932962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:28,700 - tensorflow - INFO - Saving dict for global step 100: global_step = 100, loss = 0.0029329616, masked_lm_accuracy = 1.0, masked_lm_loss = 0.002932962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: ./model_output\\model.ckpt-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:31,149 - tensorflow - INFO - Saving 'checkpoint_path' summary for global step 100: ./model_output\\model.ckpt-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:evaluation_loop marked as finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:31,152 - tensorflow - INFO - evaluation_loop marked as finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***** Eval results *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:31,152 - tensorflow - INFO - ***** Eval results *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  global_step = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:31,153 - tensorflow - INFO -   global_step = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  loss = 0.0029329616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:31,153 - tensorflow - INFO -   loss = 0.0029329616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  masked_lm_accuracy = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:31,154 - tensorflow - INFO -   masked_lm_accuracy = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  masked_lm_loss = 0.002932962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:25:31,154 - tensorflow - INFO -   masked_lm_loss = 0.002932962\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "# TPU로 BERT학습을 시키기 위한 default config 호출\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "\n",
    "tf.gfile.MakeDirs(output_dir)\n",
    "\n",
    "input_files = []\n",
    "for input_pattern in input_file.split(\",\"):\n",
    "    input_files.extend(tf.gfile.Glob(input_pattern))\n",
    "\n",
    "tf.logging.info(\"*** Input Files ***\")\n",
    "for input_file in input_files:\n",
    "    tf.logging.info(\"input_file_name:  %s\" % input_file)\n",
    "\n",
    "init_checkpoint = None\n",
    "num_warmup_steps = 10000\n",
    "use_tpu = False\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "if use_tpu and tpu_name:\n",
    "    # tpu 활성화\n",
    "    tpu_cluster_resolver = tf.estimator.tpu.cluster_resolver.TPUClusterResolver(\n",
    "        tpu_name, zone=tpu_zone, project=gcp_project)\n",
    "\n",
    "is_per_host = tf.estimator.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.estimator.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=None,\n",
    "    model_dir=output_dir,\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    tpu_config=tf.estimator.tpu.TPUConfig(\n",
    "        iterations_per_loop=1000,\n",
    "        num_shards=8,\n",
    "        per_host_input_for_training=is_per_host))\n",
    "\n",
    "# 메소드 편하게 쓰기위한 파라미터 세팅\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    init_checkpoint=init_checkpoint,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=use_tpu,\n",
    "    use_one_hot_embeddings=use_tpu)\n",
    "\n",
    "# TPU를 쓸거면 TPU 설정을 하고, TPU가 없다면, 로컬 세팅을 설정하게 됨.\n",
    "# 학습해야할 모델을 model_fn을 통해 bert로 설정한다. (modeling 클래스의 제공되는 BERT Archi)\n",
    "estimator = tf.estimator.tpu.TPUEstimator(\n",
    "    use_tpu=use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=train_batch_size,\n",
    "    eval_batch_size=eval_batch_size)\n",
    "\n",
    "if do_train:\n",
    "    # masked된 여러 샘플들을 계속 배치수만큼 꺼내서 estimator에 선언된 모델로 학습을 진행시킨다.\n",
    "    tf.logging.info(\"***** Running training *****\")\n",
    "    tf.logging.info(\"  Batch size = %d\", train_batch_size)\n",
    "    train_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=max_seq_length,\n",
    "        max_predictions_per_seq=max_predictions_per_seq,\n",
    "        is_training=True)\n",
    "    estimator.train(input_fn=train_input_fn,\n",
    "                    max_steps=num_train_steps)\n",
    "\n",
    "if do_eval:\n",
    "    tf.logging.info(\"***** Running evaluation *****\")\n",
    "    tf.logging.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    # 순서대로 그냥 만들어놓은 tfrecode값을 가져와서 하나하나 bert모델을 검증하게된다.\n",
    "    eval_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=max_seq_length,\n",
    "        max_predictions_per_seq=max_predictions_per_seq,\n",
    "        is_training=False)\n",
    "    # 모델 검증\n",
    "    result = estimator.evaluate(\n",
    "        input_fn=eval_input_fn, steps=max_eval_steps)\n",
    "    # 검증결과 저장\n",
    "    output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
    "    # pre-trained 모델 저장\n",
    "    with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
    "        tf.logging.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
