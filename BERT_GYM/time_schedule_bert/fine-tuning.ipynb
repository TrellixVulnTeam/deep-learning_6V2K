{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from salt_bert.make_preprocessed_data import tokenization\n",
    "import torch\n",
    "import os\n",
    "from huggingface_from_pretraining.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from huggingface_from_pretraining.modeling import *\n",
    "from huggingface_from_pretraining.optimization import BertAdam, warmup_linear\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "import random\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "streamHandler = logging.StreamHandler()\n",
    "# fileHandler = logging.FileHandler('./test.log')\n",
    "logger.addHandler(streamHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = True\n",
    "do_eval = True\n",
    "train_batch_size = 24\n",
    "eval_batch_size = 16\n",
    "gradient_accumulation_steps = 3\n",
    "num_train_epochs = 50\n",
    "warmup_proportion = 0.1\n",
    "fp16 = False\n",
    "learning_rate = 5e-5\n",
    "local_rank = -1\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "train_batch_size = train_batch_size // gradient_accumulation_steps\n",
    "output_dir = './model_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   str_ymd   731 non-null    object\n",
      " 1   year      731 non-null    int64 \n",
      " 2   mon       731 non-null    int64 \n",
      " 3   day       731 non-null    int64 \n",
      " 4   day_kor   731 non-null    object\n",
      " 5   weekend   731 non-null    object\n",
      " 6   holiday   731 non-null    object\n",
      " 7   str_duty  731 non-null    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning Data 로드해주세요\n",
    "\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test를 나누고 하는 것은 직접 해주셔야 합니다\n",
    "train_df_rate = math.trunc(len(tot_df)*train_rate)\n",
    "train_df = tot_df[:train_df_rate- (train_df_rate%(day_range))]\n",
    "test_df = tot_df[train_df.index[-1]+1:]\n",
    "test_df_rate = len(test_df)- (len(test_df)%day_range)\n",
    "test_df = test_df[:test_df_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\"./vocab.list\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = train_df['str_duty_x'].values.reshape(-1,7)\n",
    "train_feats_list = list(map(lambda x:' '.join(x),train_feats))\n",
    "train_labels = train_df['str_duty_y'].values.reshape(-1,7)\n",
    "train_labels_list = list(map(lambda x:' '.join(x),train_labels))\n",
    "test_feats = test_df['str_duty_x'].values.reshape(-1,7)\n",
    "test_feats_list = list(map(lambda x:' '.join(x),test_feats))\n",
    "test_labels = test_df['str_duty_y'].values.reshape(-1,7)\n",
    "test_labels_list = list(map(lambda x:' '.join(x),test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_optimization_steps = None\n",
    "if do_train:\n",
    "    num_train_optimization_steps = int(\n",
    "        len(train_feats) / train_batch_size / gradient_accumulation_steps) * num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = None\n",
    "state_dict = torch.load( os.path.join('./model_output/', 'pytorch_model.bin') )\n",
    "cache_dir = \"\" if \"\" else os.path.join(str(PYTORCH_PRETRAINED_BERT_CACHE), 'distributed_{}'.format(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading archive file ./model_output/\n",
      "Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 7\n",
      "}\n",
      "\n",
      "Weights of BertForTimeSeriesClassification not initialized from pretrained model: ['lstm_classifier.weight_ih_l0', 'lstm_classifier.weight_hh_l0', 'lstm_classifier.bias_ih_l0', 'lstm_classifier.bias_hh_l0', 'output_dense.weight', 'output_dense.bias', 'time_distributed.module.weight', 'time_distributed.module.bias']\n",
      "Weights from pretrained model not used in BertForTimeSeriesClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    }
   ],
   "source": [
    "model = BertForTimeSeriesClassification.from_pretrained('./model_output/', state_dict=state_dict, cache_dir=cache_dir, num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device: cuda n_gpu: 1, distributed training: False, 16-bits training: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTimeSeriesClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(7, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lstm_classifier): LSTM(768, 256, batch_first=True)\n",
       "  (output_dense): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (time_distributed): TimeDistributed(\n",
       "    (module): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not False else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(device, n_gpu, bool(-1 != -1), None))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                    lr=3e-5,\n",
    "                    warmup=0.1,\n",
    "                    t_total=num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "category set : ['D' 'E' 'N' 'O']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "label_list = np.unique(train_feats)\n",
    "if not os.path.isfile(os.path.join('.','label.list')):\n",
    "    with open( os.path.join('.', 'label.list'), 'wb') as f:\n",
    "        pickle.dump(label_list, f)\n",
    "else:\n",
    "    with open(os.path.join('.', 'label.list'), 'rb') as f:\n",
    "        label_list = pickle.load(f)\n",
    "logger.info(\"category set : %s\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "\t\"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "\tdef __init__(self, input_ids, input_mask, label_id):\n",
    "\t\tself.input_ids = input_ids\n",
    "\t\tself.input_mask = input_mask\n",
    "\t\tself.label_id = label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, train_labels, label_list, max_seq_length, tokenizer):\n",
    "\t\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "\tlabel_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "\tfeatures = []\n",
    "\tfor (ex_index, example) in enumerate(examples):\n",
    "\n",
    "\t\tinput_ids = tokenizer.convert_tokens_to_ids(example)\n",
    "\n",
    "\t\t# The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "\t\t# tokens are attended to.\n",
    "\t\tinput_mask = [1] * len(input_ids)\n",
    "\n",
    "\t\t# Zero-pad up to the sequence length.\n",
    "\t\tpadding = [0] * (max_seq_length - len(input_ids))\n",
    "\t\tinput_ids += padding\n",
    "\t\tinput_mask += padding\n",
    "\n",
    "\t\tassert len(input_ids) == max_seq_length\n",
    "\t\tassert len(input_mask) == max_seq_length\n",
    "\t\t#print(ex_index)\t\t\n",
    "\t\tlabel_id = list(map(lambda x:label_map[x],train_labels[ex_index]))\n",
    "\t\tif ex_index < 5:\n",
    "\t\t\tlogger.info(\"*** Example ***\")\n",
    "\t\t\tlogger.info(\"tokens: %s\" % \" \".join(\n",
    "\t\t\t\t\t[str(x) for x in example]))\n",
    "\t\t\tlogger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "\t\t\tlogger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "\t\t\tlogger.info(\"label: %s (id = %s)\" % (train_labels[ex_index], label_id))\n",
    "\n",
    "\t\tfeatures.append(\n",
    "\t\t\t\tInputFeatures(input_ids=input_ids,\n",
    "\t\t\t\t\t\t\t  input_mask=input_mask,\n",
    "\t\t\t\t\t\t\t  label_id=label_id))\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "\tlabels = labels.reshape(-1)\n",
    "\toutputs = np.argmax(out, axis=2).reshape(-1)\n",
    "\treturn np.sum(outputs == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Example ***\n",
      "tokens: O E E O E E E\n",
      "input_ids: 6 4 4 6 4 4 4\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['N' 'N' 'O' 'O' 'D' 'D' 'D'] (id = [2, 2, 3, 3, 0, 0, 0])\n",
      "*** Example ***\n",
      "tokens: N N O O D D D\n",
      "input_ids: 5 5 6 6 3 3 3\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['N' 'N' 'O' 'O' 'O' 'O' 'E'] (id = [2, 2, 3, 3, 3, 3, 1])\n",
      "*** Example ***\n",
      "tokens: N N O O O O E\n",
      "input_ids: 5 5 6 6 6 6 4\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['E' 'O' 'D' 'D' 'O' 'N' 'N'] (id = [1, 3, 0, 0, 3, 2, 2])\n",
      "*** Example ***\n",
      "tokens: E O D D O N N\n",
      "input_ids: 4 6 3 3 6 5 5\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['O' 'O' 'E' 'E' 'E' 'O' 'D'] (id = [3, 3, 1, 1, 1, 3, 0])\n",
      "*** Example ***\n",
      "tokens: O O E E E O D\n",
      "input_ids: 6 6 4 4 4 6 3\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['D' 'O' 'O' 'O' 'D' 'N' 'N'] (id = [0, 3, 3, 3, 0, 2, 2])\n",
      "***** Running training *****\n",
      "  Num examples = 47\n",
      "  Batch size = 8\n",
      "  Num steps = 50\n",
      "*** Example ***\n",
      "tokens: E N N O O N N\n",
      "input_ids: 4 5 5 6 6 5 5\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['O' 'O' 'O' 'D' 'D' 'D' 'E'] (id = [3, 3, 3, 0, 0, 0, 1])\n",
      "*** Example ***\n",
      "tokens: O O O D D D E\n",
      "input_ids: 6 6 6 3 3 3 4\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['O' 'D' 'D' 'O' 'O' 'N' 'N'] (id = [3, 0, 0, 3, 3, 2, 2])\n",
      "*** Example ***\n",
      "tokens: O D D O O N N\n",
      "input_ids: 6 3 3 6 6 5 5\n",
      "input_mask: 1 1 1 1 1 1 1\n",
      "label: ['O' 'O' 'E' 'E' 'E' 'E' 'O'] (id = [3, 3, 1, 1, 1, 1, 3])\n",
      "***** Running evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▏         | 1/50 [00:01<00:51,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 4\n",
      "Epoch:   4%|▍         | 2/50 [00:01<00:31,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 6\n",
      "Epoch:   6%|▌         | 3/50 [00:01<00:24,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 8\n",
      "Epoch:   8%|▊         | 4/50 [00:02<00:21,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 10\n",
      "Epoch:  10%|█         | 5/50 [00:02<00:19,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 12\n",
      "Epoch:  12%|█▏        | 6/50 [00:02<00:18,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 14\n",
      "Epoch:  14%|█▍        | 7/50 [00:03<00:17,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 16\n",
      "Epoch:  16%|█▌        | 8/50 [00:03<00:16,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 18\n",
      "Epoch:  18%|█▊        | 9/50 [00:04<00:15,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 20\n",
      "Epoch:  20%|██        | 10/50 [00:04<00:15,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 22\n",
      "Epoch:  22%|██▏       | 11/50 [00:04<00:15,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n",
      "torch.Size([3, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Eval results *****\n",
      "  eval_accuracy = 0.42857142857142855\n",
      "  global_step = 24\n",
      "Epoch:  24%|██▍       | 12/50 [00:05<00:14,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([8, 7, 256])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 12/50 [00:05<00:17,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([8, 7, 256])\n",
      "torch.Size([7, 7, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-9839bd3e40d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m                                         \u001b[1;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                                                 \u001b[0mparam_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_this_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                                 \u001b[0mglobal_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\workspace_jupyter\\embedding_test\\pytorch_pretrained_bert\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;31m# Add grad clipping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_grad_norm'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                     \u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_grad_norm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m   1374\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[0m_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# noqa: C416 TODO: rewrite as list(range(m))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m     \u001b[1;31m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0\n",
    "\n",
    "max_seq_length = 7\n",
    "if do_train:\n",
    "\ttrain_features = convert_examples_to_features(train_feats, train_labels, label_list, max_seq_length, tokenizer)\n",
    "\tlogger.info(\"***** Running training *****\")\n",
    "\tlogger.info(\"  Num examples = %d\", len(train_feats))\n",
    "\tlogger.info(\"  Batch size = %d\", train_batch_size)\n",
    "\tlogger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "\tall_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "\tall_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "\tall_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "\ttrain_data = TensorDataset(all_input_ids, all_input_mask, all_label_ids)\n",
    "\ttrain_sampler = RandomSampler(train_data)\n",
    "\ttrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "\tif do_eval and (local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "\t\teval_features = convert_examples_to_features(test_feats, test_labels, label_list, max_seq_length, tokenizer)\n",
    "\t\tlogger.info(\"***** Running evaluation *****\")\n",
    "\t\tlogger.info(\"  Num examples = %d\", len(test_feats))\n",
    "\t\tlogger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "\t\tall_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "\t\tall_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "\t\tall_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "\t\teval_data = TensorDataset(all_input_ids, all_input_mask, all_label_ids)\n",
    "\t\t# Run prediction for full data\n",
    "\t\teval_sampler = SequentialSampler(eval_data)\n",
    "\t\teval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "\tfor epoch_i in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "\t\tmodel.train()\n",
    "\t\ttr_loss = 0\n",
    "\t\tnb_tr_examples, nb_tr_steps = 0, 0\n",
    "\t\t\n",
    "\t\tfor step, batch in enumerate(train_dataloader):\n",
    "\t\t\tbatch = tuple(t.to(device) for t in batch)\n",
    "\t\t\tinput_ids, input_mask, label_ids = batch\n",
    "\t\t\thidden = torch.zeros(1, batch[0].size()[0], 256, requires_grad=True, device=device)\n",
    "\t\t\tcell = torch.zeros(1, batch[0].size()[0], 256, requires_grad=True, device=device)\n",
    "\t\t\tloss = model(input_ids, input_mask, label_ids, (hidden,cell))\n",
    "\t\t\tif n_gpu > 1:\n",
    "\t\t\t\tloss = loss.mean() # mean() to average on multi-gpu.\n",
    "\t\t\tif gradient_accumulation_steps > 1:\n",
    "\t\t\t\tloss = loss / gradient_accumulation_steps\n",
    "\n",
    "\t\t\tif fp16:\n",
    "\t\t\t\toptimizer.backward(loss)\n",
    "\t\t\telse:\n",
    "\t\t\t\tloss.backward()\n",
    "\n",
    "\t\t\ttr_loss += loss.item()\n",
    "\t\t\tnb_tr_examples += input_ids.size(0)\n",
    "\t\t\tnb_tr_steps += 1\n",
    "\t\t\tif (step + 1) % gradient_accumulation_steps == 0:\n",
    "\t\t\t\tif fp16:\n",
    "\t\t\t\t\t# modify learning rate with special warm up BERT uses\n",
    "\t\t\t\t\t# if fp16 is False, BertAdam is used that handles this automatically\n",
    "\t\t\t\t\tlr_this_step = learning_rate * warmup_linear(global_step/num_train_optimization_steps, warmup_proportion)\n",
    "\t\t\t\t\tfor param_group in optimizer.param_groups:\n",
    "\t\t\t\t\t\tparam_group['lr'] = lr_this_step\n",
    "\t\t\t\toptimizer.step()\n",
    "\t\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\tglobal_step += 1\n",
    "\t\t\t\n",
    "\t\t\tif nb_tr_steps != 0 and nb_tr_steps % 100 == 0 :\n",
    "\t\t\t\tlogger.info ( '[train]\\t%d\\t%d\\t%f' % (nb_tr_steps, nb_tr_examples, tr_loss / nb_tr_examples*1.0) )\n",
    "\n",
    "\t\tif do_eval and (local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "\t\t\tmodel.eval()\n",
    "\t\t\teval_accuracy = 0.0\n",
    "\t\t\tnb_eval_examples = 0\n",
    "\n",
    "\t\t\tfor input_ids, input_mask, label_ids in eval_dataloader:\n",
    "\t\t\t\tinput_ids = input_ids.to(device)\n",
    "\t\t\t\tinput_mask = input_mask.to(device)\n",
    "\t\t\t\tlabel_ids = label_ids.to(device)\n",
    "\n",
    "\t\t\t\twith torch.no_grad():\n",
    "\t\t\t\t\tlogits = model(input_ids, input_mask)\n",
    "\n",
    "\t\t\t\tlogits = logits.detach().cpu().numpy()\n",
    "\t\t\t\tlabel_ids = label_ids.to('cpu').numpy()\n",
    "\t\t\t\t\n",
    "\t\t\t\teval_accuracy += accuracy(logits, label_ids)\n",
    "\n",
    "\t\t\t\tnb_eval_examples = (input_ids.size(0)*input_ids.size(1)) + nb_eval_examples\n",
    "\t\t\teval_accuracy = eval_accuracy / nb_eval_examples\n",
    "\t\t\tresult = {'eval_accuracy': eval_accuracy,\n",
    "\t\t\t\t\t\t'global_step': global_step}\n",
    "\t\t\tlogger.info(\"***** Eval results *****\")\n",
    "\t\t\tfor key in sorted(result.keys()):\n",
    "\t\t\t\tlogger.info(\"  %s = %s\", key, str(result[key]))\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t\tif output_dir != None and epoch_i%25==0:\n",
    "\t\t\tmodel_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "\t\t\toutput_model_file = os.path.join(output_dir, \"pytorch_model_e%d.bin\" % epoch_i)\n",
    "\t\t\ttorch.save(model_to_save.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 256])\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# 예측 테스트\n",
    "\n",
    "input_tokens=['D','E','N','O','O','E','E']\n",
    "input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "input_ids = torch.tensor([input_ids], dtype=torch.long)\n",
    "input_mask = torch.tensor([[1,1,1,1,1,1,1]], dtype=torch.long)\n",
    "input_ids = input_ids.to(device)\n",
    "input_mask = input_mask.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(input_ids, input_mask)\n",
    "\n",
    "logits = logits.detach().cpu().numpy()\n",
    "# label_ids = label_ids.to('cpu').numpy()\n",
    "print(list(map(lambda x:label_list[x],np.argmax(logits,axis=2).reshape(-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하기 내용들은, 값을 테스트해보기 위해 사용한 블락들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./test.txt',model.bert.embeddings(input_ids).detach().cpu().numpy().reshape(-1,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.bert.embeddings(input_ids).detach().cpu().numpy().reshape(-1,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054612</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>-0.082023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.054612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.056569</td>\n",
       "      <td>-0.012214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.009569</td>\n",
       "      <td>-0.056569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.082023</td>\n",
       "      <td>-0.012214</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.000000 -0.054612 -0.009569 -0.082023\n",
       "1 -0.054612  1.000000 -0.056569 -0.012214\n",
       "2 -0.009569 -0.056569  1.000000  0.000704\n",
       "3 -0.082023 -0.012214  0.000704  1.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.corrcoef(embed[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_output,_ = model.bert(input_ids,input_mask,False)\n",
    "sequence_output = sequence_output.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7252, -2.1268,  0.7987,  ..., -1.3268,  1.3964,  2.2400],\n",
       "         [ 1.7252, -2.1268,  0.7987,  ..., -1.3268,  1.3964,  2.2400],\n",
       "         [ 1.7252, -2.1268,  0.7987,  ..., -1.3268,  1.3964,  2.2400],\n",
       "         ...,\n",
       "         [ 1.7252, -2.1268,  0.7987,  ..., -1.3268,  1.3964,  2.2400],\n",
       "         [ 1.7252, -2.1268,  0.7987,  ..., -1.3268,  1.3964,  2.2400],\n",
       "         [ 1.7252, -2.1268,  0.7987,  ..., -1.3268,  1.3964,  2.2400]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.9078413 , -0.80583738],\n",
       "       [ 0.9078413 ,  1.        , -0.97986371],\n",
       "       [-0.80583738, -0.97986371,  1.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.array([[0.8, 0.3, 0.1],\n",
    "[0.7, 0.5, 0.1],\n",
    "[0.1, 0.2, 0.8]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
