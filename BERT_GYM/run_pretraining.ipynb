{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 17:52:32.558627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 17:52:33.438314: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-08 17:52:33.439153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-08 17:52:33.466807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-08 17:52:33.467268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-08 17:52:33.467280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-08 17:52:33.471056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-08 17:52:33.471081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-11-08 17:52:33.472884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-08 17:52:33.473084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-08 17:52:33.473507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-08 17:52:33.474319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-11-08 17:52:33.474414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-11-08 17:52:33.476310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from salt_bert.make_bert_model import modeling\n",
    "from salt_bert.make_bert_model import optimization\n",
    "import tensorflow.compat.v1 as tf\n",
    "import time\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(physical_devices[0],'GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = model.get_sequence_output : BERT 모델의 encoder 마지막 hidden layer(인코더의 마지막.)\n",
    "# model의 마지막 레이어의 output은 멀티헤드 sequence_attention_masked에 따라간다.\n",
    "# output_weights = embedding_table : input_ids들의 워드 임베딩 테이블 (단어 위치사전)\n",
    "def get_masked_lm_output(bert_config, input_tensor, output_weights, positions, label_ids, label_weights):\n",
    "    \"\"\"Get loss and log probs for the masked LM.\"\"\"\n",
    "    input_tensor = gather_indexes(input_tensor, positions)\n",
    "\n",
    "    with tf.variable_scope(\"cls/predictions\"):\n",
    "        # 학습하기 위한 첫번째 레이어\n",
    "        # 모델의 전부를 활용하는 것이 아닌, \n",
    "        with tf.variable_scope(\"transform\"):\n",
    "            input_tensor = tf.layers.dense(\n",
    "                input_tensor,\n",
    "                units=bert_config.hidden_size,\n",
    "                activation=modeling.get_activation(bert_config.hidden_act),\n",
    "                kernel_initializer=modeling.create_initializer(\n",
    "                    bert_config.initializer_range))\n",
    "            input_tensor = modeling.layer_norm(input_tensor)\n",
    "\n",
    "        # wx+b를 통해서, 뭔가 분류하려고함.\n",
    "        output_bias = tf.get_variable(\n",
    "            \"output_bias\",\n",
    "            shape=[bert_config.vocab_size],\n",
    "            initializer=tf.zeros_initializer())\n",
    "        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        label_ids = tf.reshape(label_ids, [-1])\n",
    "        label_weights = tf.reshape(label_weights, [-1])\n",
    "\n",
    "        # 원핫 인코딩 된 예측값을, 실제값으로도 원핫시켜 맞추고자함.\n",
    "        one_hot_labels = tf.one_hot(\n",
    "            label_ids, depth=bert_config.vocab_size, dtype=tf.float32)\n",
    "\n",
    "        # 포지션 텐서는 문장 길이에 따라 제로 패딩이 존재할 수 있다.\n",
    "        \n",
    "        # label_weights는 실제 값에 대해서는 1.0을 가지고, 패딩 예측에 대해서는 0을 가지도록 하겠다.\n",
    "        # 우리는 masked를 맞추고 싶기 때문에, masked에 집중하는 것이 필요하다. (즉 전체 loss를 계산할 이유가 없음)\n",
    "        # 따라서 log_softmax를 사용하여, 비선형으로 변환한다음 weight를 적용하고, 해당 weight가 적용된 놈들의 평균적인 오차만 보겠다는 것이다.\n",
    "        # 이를 log_softmax+Negative Log Likelihood Loss라고 한다.\n",
    "        \n",
    "        # Sum과 Mean을 하는 방식이 있는데, 현재 방식에서는 보고싶은 만큼을 Mean하는 방식을 사용했고, Torch에서는 NLLLoss가 제공되나, TF에는 제공되지 않아 직접 작성한듯 보인다.\n",
    "        \n",
    "        # 예시) 개, 고양이, 말 중 개를 찾고싶다. (개 1,0,0)\n",
    "        # softmax 시, 0.8, 0.1, 0.1이다. => onehot과 곱하면 0.8만 남음\n",
    "        # -log(0.8) => 0에 수렴함. 즉 loss가 낮음\n",
    "        # softmax 시, 0.1 0.1 0.8이다. => onehoy과 곱하면 0.1만 남음\n",
    "        # -log(0.1) => 1에 수렴함. 즉 loss가 높음\n",
    "        # 을 이용해서 학습시키는 방식.\n",
    "        \n",
    "        # 예측한 토큰의 가능성을 지닌 array 넘버를, onehot을 이용하여 곱해서 찾게되므로, 결국 실제 문자열과 비교하는 동일한 효과가 난다.\n",
    "        \n",
    "        # softmax 가능성 중, 정답으로 맞춰야할 곳을 찾음 (각 masked token 별 가장 label에 대응되는 부분의 가능성이 추출됨)\n",
    "        per_example_loss = - \\\n",
    "            tf.reduce_sum(log_probs*one_hot_labels, axis=[-1])\n",
    "        \n",
    "        # 정답으로 맞춰야할 곳을 전부 다 더하면, 잘 가리켰으면, loss가 낮을것이고, 아니면 loss가 높게됨\n",
    "        # 실제 masked인 곳만 예측할 것이므로, label_weights를 곱해서 아닌곳은 자동으로 0이됨\n",
    "        numerator = tf.reduce_sum(label_weights * per_example_loss)\n",
    "        \n",
    "        # masked한 놈들만 loss 집계를 실시함 (Mean)\n",
    "        denominator = tf.reduce_sum(label_weights) + 1e-5    # + EPS (1e-5)\n",
    "        loss = numerator / denominator\n",
    "\n",
    "    return (loss, per_example_loss, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train=True \n",
    "do_eval=True \n",
    "train_batch_size=4\n",
    "eval_batch_size = 8\n",
    "max_eval_steps = 100\n",
    "max_seq_length=512 \n",
    "max_predictions_per_seq=20 \n",
    "num_train_steps=10 \n",
    "learning_rate=1e-4 \n",
    "save_checkpoints_steps=5 \n",
    "do_lower_case=False\n",
    "bert_config_file='./config/bert_config.json'\n",
    "input_file='./wiki_20190620_small_512_tf.record'\n",
    "output_dir='pre_trained_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n",
    "                     num_train_steps, num_warmup_steps, use_tpu,\n",
    "                     use_one_hot_embeddings):\n",
    "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "\n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        import sys\n",
    "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "        tf.logging.info(\"*** Features ***\")\n",
    "        for name in sorted(features.keys()):\n",
    "            tf.logging.info(\"  name = %s, shape = %s\" %\n",
    "                            (name, features[name].shape))\n",
    "\n",
    "        # 특징 값 설정\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        masked_lm_positions = features[\"masked_lm_positions\"]\n",
    "        masked_lm_ids = features[\"masked_lm_ids\"]\n",
    "        masked_lm_weights = features[\"masked_lm_weights\"]\n",
    "        next_sentence_labels = features[\"next_sentence_labels\"]\n",
    "        \n",
    "        # train default\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        \n",
    "        # bertmodel 호출\n",
    "        # input_ids -> 문장벡터\n",
    "        # input_mask -> input이 존재하는지 여부. (0 패딩에 대해서는 MASK 패널티를 부여하여, Attention하지 못하도록 함.)\n",
    "        # token_type_ids -> segment_ids : 문장 순서 앞문장 0 뒷문장 1\n",
    "        model = modeling.BertModel(\n",
    "            config=bert_config,\n",
    "            is_training=is_training,\n",
    "            input_ids=input_ids,\n",
    "            input_mask=input_mask,\n",
    "            token_type_ids=segment_ids,\n",
    "            use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "        \n",
    "        # model.get_sequence_output : BERT 모델의 encoder 마지막 hidden layer(인코더의 마지막.)\n",
    "        (masked_lm_loss,\n",
    "         masked_lm_example_loss, masked_lm_log_probs) = get_masked_lm_output(\n",
    "             bert_config, model.get_sequence_output(), model.get_embedding_table(),\n",
    "             masked_lm_positions, masked_lm_ids, masked_lm_weights)\n",
    "\n",
    "        (next_sentence_loss, next_sentence_example_loss,\n",
    "         next_sentence_log_probs) = get_next_sentence_output(\n",
    "             bert_config, model.get_pooled_output(), next_sentence_labels)\n",
    "\n",
    "        total_loss = masked_lm_loss + next_sentence_loss\n",
    "        tf.print(\"tensors_test : \", total_loss, output_stream=sys.stdout)\n",
    "        tvars = tf.trainable_variables()\n",
    "\n",
    "        initialized_variable_names = {}\n",
    "        scaffold_fn = None\n",
    "        if init_checkpoint:\n",
    "            (assignment_map, initialized_variable_names\n",
    "             ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "            if use_tpu:\n",
    "\n",
    "                def tpu_scaffold():\n",
    "                    tf.train.init_from_checkpoint(\n",
    "                        init_checkpoint, assignment_map)\n",
    "                    return tf.train.Scaffold()\n",
    "\n",
    "                scaffold_fn = tpu_scaffold\n",
    "            else:\n",
    "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "\n",
    "        tf.logging.info(\"**** Trainable Variables ****\")\n",
    "        for var in tvars:\n",
    "            init_string = \"\"\n",
    "            if var.name in initialized_variable_names:\n",
    "                init_string = \", *INIT_FROM_CKPT*\"\n",
    "            tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "                            init_string)\n",
    "\n",
    "        output_spec = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = optimization.create_optimizer(\n",
    "                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
    "\n",
    "            output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                train_op=train_op,\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "            def metric_fn(masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
    "                          masked_lm_weights, next_sentence_example_loss,\n",
    "                          next_sentence_log_probs, next_sentence_labels):\n",
    "                \"\"\"Computes the loss and accuracy of the model.\"\"\"\n",
    "                masked_lm_log_probs = tf.reshape(masked_lm_log_probs,\n",
    "                                                 [-1, masked_lm_log_probs.shape[-1]])\n",
    "                masked_lm_predictions = tf.argmax(\n",
    "                    masked_lm_log_probs, axis=-1, output_type=tf.int32)\n",
    "                masked_lm_example_loss = tf.reshape(\n",
    "                    masked_lm_example_loss, [-1])\n",
    "                masked_lm_ids = tf.reshape(masked_lm_ids, [-1])\n",
    "                masked_lm_weights = tf.reshape(masked_lm_weights, [-1])\n",
    "                masked_lm_accuracy = tf.metrics.accuracy(\n",
    "                    labels=masked_lm_ids,\n",
    "                    predictions=masked_lm_predictions,\n",
    "                    weights=masked_lm_weights)\n",
    "                masked_lm_mean_loss = tf.metrics.mean(\n",
    "                    values=masked_lm_example_loss, weights=masked_lm_weights)\n",
    "\n",
    "                next_sentence_log_probs = tf.reshape(\n",
    "                    next_sentence_log_probs, [-1, next_sentence_log_probs.shape[-1]])\n",
    "                next_sentence_predictions = tf.argmax(\n",
    "                    next_sentence_log_probs, axis=-1, output_type=tf.int32)\n",
    "                next_sentence_labels = tf.reshape(next_sentence_labels, [-1])\n",
    "                next_sentence_accuracy = tf.metrics.accuracy(\n",
    "                    labels=next_sentence_labels, predictions=next_sentence_predictions)\n",
    "                next_sentence_mean_loss = tf.metrics.mean(\n",
    "                    values=next_sentence_example_loss)\n",
    "\n",
    "                return {\n",
    "                    \"masked_lm_accuracy\": masked_lm_accuracy,\n",
    "                    \"masked_lm_loss\": masked_lm_mean_loss,\n",
    "                    \"next_sentence_accuracy\": next_sentence_accuracy,\n",
    "                    \"next_sentence_loss\": next_sentence_mean_loss,\n",
    "                }\n",
    "\n",
    "            eval_metrics = (metric_fn, [\n",
    "                masked_lm_example_loss, masked_lm_log_probs, masked_lm_ids,\n",
    "                masked_lm_weights, next_sentence_example_loss,\n",
    "                next_sentence_log_probs, next_sentence_labels\n",
    "            ])\n",
    "            output_spec = tf.estimator.tpu.TPUEstimatorSpec(\n",
    "                mode=mode,\n",
    "                loss=total_loss,\n",
    "                eval_metrics=eval_metrics,\n",
    "                scaffold_fn=scaffold_fn)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Only TRAIN and EVAL modes are supported: %s\" % (mode))\n",
    "\n",
    "        return output_spec\n",
    "\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.to_int32(t)\n",
    "        example[name] = t\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(input_files,\n",
    "                     max_seq_length,\n",
    "                     max_predictions_per_seq,\n",
    "                     is_training,\n",
    "                     num_cpu_threads=4):\n",
    "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "    def input_fn(params):\n",
    "        \"\"\"The actual input function.\"\"\"\n",
    "        batch_size = params[\"batch_size\"]\n",
    "\n",
    "        name_to_features = {\n",
    "            \"input_ids\":\n",
    "                tf.FixedLenFeature([max_seq_length], tf.int64),\n",
    "            \"input_mask\":\n",
    "                tf.FixedLenFeature([max_seq_length], tf.int64),\n",
    "            \"segment_ids\":\n",
    "                tf.FixedLenFeature([max_seq_length], tf.int64),\n",
    "            \"masked_lm_positions\":\n",
    "                tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "            \"masked_lm_ids\":\n",
    "                tf.FixedLenFeature([max_predictions_per_seq], tf.int64),\n",
    "            \"masked_lm_weights\":\n",
    "                tf.FixedLenFeature([max_predictions_per_seq], tf.float32),\n",
    "            \"next_sentence_labels\":\n",
    "                tf.FixedLenFeature([1], tf.int64),\n",
    "        }\n",
    "\n",
    "        # 트레이닝을 위해서 많은 데이터를 병렬로 읽고 셔플해야한다.\n",
    "        # 검증을 위해서는, 병렬처리는 상관없으나 셔플이 되면 안된다.\n",
    "        if is_training:\n",
    "            d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))\n",
    "            d = d.repeat()    # epoch 설정인데, 디폴트 무제한\n",
    "            d = d.shuffle(buffer_size=len(input_files))    # 에포크별 섞을지\n",
    "\n",
    "            # cpu 스레드 갯수만큼 읽을때 병렬처리 할 것임.\n",
    "            cycle_length = min(num_cpu_threads, len(input_files))\n",
    "\n",
    "            # interleave를 통해서, 데이터를 끼워넣게 되므로, 좀 더 자연스러운 랜덤구현이 가능해진다.\n",
    "            # sloppy는 그냥 병렬로 들어오는애들 다집어넣는다.\n",
    "            d = d.apply(\n",
    "                tf.data.experimental.parallel_interleave(\n",
    "                    tf.data.TFRecordDataset,\n",
    "                    sloppy=is_training,\n",
    "                    cycle_length=cycle_length))\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "        else:\n",
    "            d = tf.data.TFRecordDataset(input_files)\n",
    "            # 검증시에는 갑작스러운 out of range 발생을 원하지 않으니, 숫자를 정해서 수행하자.\n",
    "            d = d.repeat()\n",
    "\n",
    "        # TPU학습은 차원을 고정해야만 하기때문에, drop_remainder를 사용하여, 배치에 담기지 못하는 부분은 버린다\n",
    "        # 검증을 위해서, 혹은 CPU나 GPU를 사용한다면, drop_remainder를 원하지 않을 수 있다. 뭐 그러면, 모든 샘플을 활용 가능하것지만.\n",
    "        d = d.apply(\n",
    "            tf.data.experimental.map_and_batch(\n",
    "                lambda record: _decode_record(record, name_to_features),\n",
    "                batch_size=batch_size,\n",
    "                num_parallel_batches=num_cpu_threads,\n",
    "                drop_remainder=True))\n",
    "        return d\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_indexes(sequence_tensor, positions):\n",
    "    \"\"\"배치에 들어갈 알맞은 차원으로 변환시킴\"\"\"\n",
    "    # 고정된 모든 차원의 텐서그래프가 리턴됨. expected_rank는 만약 텐서리스트중 그에 안맞는게 있으면, 에러 리턴됨\n",
    "    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n",
    "\n",
    "    # lstm형태로 넘기기 위해 결정하는 것으로 판단됨.\n",
    "    batch_size = sequence_shape[0]\n",
    "    seq_length = sequence_shape[1]\n",
    "    width = sequence_shape[2]\n",
    "\n",
    "    flat_offsets = tf.reshape(\n",
    "        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n",
    "    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n",
    "    flat_sequence_tensor = tf.reshape(sequence_tensor,\n",
    "                                      [batch_size * seq_length, width])\n",
    "    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_sentence_output(bert_config, input_tensor, labels):\n",
    "    \"\"\"Get loss and log probs for the next sentence prediction.\"\"\"\n",
    "\n",
    "    # Simple binary classification. Note that 0 is \"next sentence\" and 1 is\n",
    "    # \"random sentence\". This weight matrix is not used after pre-training.\n",
    "    with tf.variable_scope(\"cls/seq_relationship\"):\n",
    "        output_weights = tf.get_variable(\n",
    "            \"output_weights\",\n",
    "            shape=[2, bert_config.hidden_size],\n",
    "            initializer=modeling.create_initializer(bert_config.initializer_range))\n",
    "        output_bias = tf.get_variable(\n",
    "            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n",
    "\n",
    "        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "        labels = tf.reshape(labels, [-1])\n",
    "        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, per_example_loss, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Input Files ***\n",
      "INFO:tensorflow:input_file_name:  ./wiki_20190620_small_512_tf.record\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f18a841bf70>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'pre_trained_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Batch size = 4\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU/GPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (8, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (8, 512)\n",
      "INFO:tensorflow:  name = masked_lm_ids, shape = (8, 20)\n",
      "INFO:tensorflow:  name = masked_lm_positions, shape = (8, 20)\n",
      "INFO:tensorflow:  name = masked_lm_weights, shape = (8, 20)\n",
      "INFO:tensorflow:  name = next_sentence_labels, shape = (8, 1)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (8, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (49541, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/layer_normalization/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/embeddings/layer_normalization/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/layer_normalization_1/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/layer_normalization_1/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/layer_normalization_2/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/layer_normalization_2/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/layer_normalization_3/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/layer_normalization_3/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/layer_normalization_4/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/layer_normalization_4/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/layer_normalization_5/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/layer_normalization_5/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/layer_normalization_6/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/layer_normalization_6/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/layer_normalization_7/gamma:0, shape = (768,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/layer_normalization_7/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/layer_normalization_8/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/layer_normalization_8/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/layer_normalization_9/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/layer_normalization_9/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/layer_normalization_10/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/layer_normalization_10/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/layer_normalization_11/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/layer_normalization_11/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/layer_normalization_12/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/layer_normalization_12/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/layer_normalization_13/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/layer_normalization_13/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/layer_normalization_14/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/layer_normalization_14/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/layer_normalization_15/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/layer_normalization_15/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/layer_normalization_16/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/layer_normalization_16/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/layer_normalization_17/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/layer_normalization_17/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/layer_normalization_18/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/layer_normalization_18/beta:0, shape = (768,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/layer_normalization_19/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/layer_normalization_19/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/layer_normalization_20/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/layer_normalization_20/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/layer_normalization_21/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/layer_normalization_21/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/layer_normalization_22/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/layer_normalization_22/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/layer_normalization_23/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/layer_normalization_23/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/layer_normalization_24/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/layer_normalization_24/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/layer_normalization_25/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/transform/layer_normalization_25/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (49541,)\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-11-08T17:55:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pre_trained_model/model.ckpt-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 17:55:37.739350: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-08 17:55:37.740318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-08 17:55:37.740857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-11-08 17:55:37.740892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-08 17:55:37.740968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-08 17:55:37.740978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-11-08 17:55:37.740987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-08 17:55:37.740995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-08 17:55:37.741003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-08 17:55:37.741011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-11-08 17:55:37.741020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-11-08 17:55:37.742324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2021-11-08 17:55:37.742390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-08 17:55:37.742397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2021-11-08 17:55:37.742401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2021-11-08 17:55:37.742404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2021-11-08 17:55:37.743327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13739 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:37:00.0, compute capability: 7.5)\n",
      "2021-11-08 17:55:37.743797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13739 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:86:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-11.2532444 -9.93661118 -10.7432594...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1889915 -10.293396 -10.8487825...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.4981136 -10.6479282 -11.4589844...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3327847 -10.7249603 -11.0813942...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3407221 -10.5844898 -11.6017532...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-9.90637302 -10.5846748 -11.0964069...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.576705 -11.1787281 -11.3835096...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.4638062 -10.8268309 -12.0053387...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.177001 -11.0360613 -11.4168816...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-11.6780186 -10.4887266 -11.5300179...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0116673 -10.159771 -10.9922562...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.7483864 -9.90176773 -11.2590647...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0872116 -10.8404236 -11.4293461...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3021755 -10.3228931 -11.4572802...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.8385258 -10.0758495 -11.1788177...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0037642 -10.6429071 -11.1645308...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3405437 -10.7013836 -11.0775576...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1874084 -10.7461014 -11.3669081...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.5725784 -11.2075901 -11.4332256...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-11.3502579 -10.7513514 -11.3905363...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.4091473 -10.5696764 -11.3755713...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.703166 -10.5312786 -11.0302839...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0484095 -10.3968544 -11.5812731...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1067371 -10.4118824 -11.3543...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.6094141 -10.5736275 -11.2626514...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3011255 -10.456707 -11.3562794...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.5379181 -10.789156 -11.4001942...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3391342 -10.7093945 -11.472024...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1114435 -11.041934 -11.6757584...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-10.7668066 -10.4386435 -10.7637...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.70502 -11.3767052 -11.0509253...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.4963779 -10.836359 -11.2806377...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.8310423 -10.3482246 -10.8335981...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.7410555 -10.2569895 -11.1401825...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.9772148 -10.4047832 -11.0395031...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.5551853 -10.8517551 -11.3681173...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.8842773 -10.2817984 -11.2006569...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.3459835 -11.1530695 -10.45049...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0218935 -10.5109138 -10.8068209...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-10.6275597 -10.4232616 -11.2453232...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0663357 -10.3669615 -11.6057549...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.8183937 -10.7777176 -11.2439079...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.4604416 -10.9334621 -11.1496534...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2783527 -10.1039314 -11.8669987...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.7724304 -10.760067 -10.9152851...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.238163 -10.6537046 -11.3570375...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3020992 -10.7877798 -11.6815586...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0472164 -10.5512991 -11.0453548...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.9587975 -10.5437107 -10.954998...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-10.9337902 -10.7044611 -11.4199762...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2154551 -10.6642561 -11.1224604...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0938768 -10.757452 -11.4941...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3878193 -9.97363186 -11.3832655...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2042274 -10.543705 -10.8290691...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.8213673 -10.5261536 -11.7197456...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.4267139 -10.7701969 -11.4852266...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.15798 -10.527606 -11.253829...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0856209 -10.4644985 -11.6133299...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2163696 -10.8181858 -11.6342173...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-11.0389385 -10.519865 -11.0942793...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2933426 -10.2573051 -11.2034626...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3769436 -10.3874102 -10.8738108...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.9547348 -10.1218147 -11.7036171...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.4352026 -10.3272772 -11.2023315...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2632256 -10.7011242 -11.6705265...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.5220871 -10.8322983 -11.68009...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0212507 -10.3645296 -11.568306...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-9.95130539 -10.8387928 -11.2234535...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.9011803 -10.630496 -11.4339256...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-11.5722065 -10.7173386 -11.7199602...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.4819202 -11.1431656 -11.2725735...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0199137 -11.1860704 -11.4715405...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.020751 -10.6321812 -11.4617596...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.900691 -10.0849609 -10.9934244...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2621231 -11.1292152 -11.1718044...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.5254774 -10.1858635 -11.1921368...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.8782301 -10.5711918 -10.7220068...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2471619 -10.5999413 -10.3054733...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.6463566 -10.1340246 -11.6715946...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-10.5352726 -11.0259953 -11.3392572...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.9175148 -9.98015213 -11.4186316...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1756992 -10.8146811 -11.4268026...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.1295471 -10.7427368 -10.1819792...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.0404444 -10.472312 -11.2368355...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.5433216 -10.1752186 -11.0624371...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.7869949 -10.5038691 -10.8957453...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.3009119 -10.9649725 -11.5893965...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1945219 -10.8359022 -10.6126041...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2337866 -10.7032194 -12.0161619...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-11.1354837 -10.339716 -11.9649706...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.6882162 -10.4133949 -11.0588541...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.2636166 -10.5157776 -11.1691494...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.9053087 -10.5089436 -12.1178379...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.6565971 -10.5251198 -11.1874428...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.4425611 -10.6271381 -12.0862961...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.5617285 -10.6145697 -11.8146563...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-10.4256525 -10.4260368 -11.4061928...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1544781 -10.4420176 -10.7749882...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n",
      "log_probs : [-11.1053448 -10.2356796 -11.1421165...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Inference Time : 33.58694s\n",
      "INFO:tensorflow:Finished evaluation at 2021-11-08-17:56:11\n",
      "INFO:tensorflow:Saving dict for global step 10: global_step = 10, loss = 541354.0, masked_lm_accuracy = 0.0, masked_lm_loss = 541353.4, next_sentence_accuracy = 0.4975, next_sentence_loss = 0.6928569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_probs : [-10.9673367 -10.0335464 -11.5789871...]\n",
      "one_hot_labels : [0 0 0...]\n",
      "test : [-0 -0 -0...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: pre_trained_model/model.ckpt-10\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  global_step = 10\n",
      "INFO:tensorflow:  loss = 541354.0\n",
      "INFO:tensorflow:  masked_lm_accuracy = 0.0\n",
      "INFO:tensorflow:  masked_lm_loss = 541353.4\n",
      "INFO:tensorflow:  next_sentence_accuracy = 0.4975\n",
      "INFO:tensorflow:  next_sentence_loss = 0.6928569\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "# TPU로 BERT학습을 시키기 위한 default config 호출\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "\n",
    "tf.gfile.MakeDirs(output_dir)\n",
    "\n",
    "input_files = []\n",
    "for input_pattern in input_file.split(\",\"):\n",
    "    input_files.extend(tf.gfile.Glob(input_pattern))\n",
    "\n",
    "tf.logging.info(\"*** Input Files ***\")\n",
    "for input_file in input_files:\n",
    "    tf.logging.info(\"input_file_name:  %s\" % input_file)\n",
    "\n",
    "init_checkpoint = None\n",
    "num_warmup_steps = 10000\n",
    "use_tpu = False\n",
    "\n",
    "tpu_cluster_resolver = None\n",
    "if use_tpu and tpu_name:\n",
    "    # tpu 활성화\n",
    "    tpu_cluster_resolver = tf.estimator.tpu.cluster_resolver.TPUClusterResolver(\n",
    "        tpu_name, zone=tpu_zone, project=gcp_project)\n",
    "\n",
    "is_per_host = tf.estimator.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.estimator.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    master=None,\n",
    "    model_dir=output_dir,\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    tpu_config=tf.estimator.tpu.TPUConfig(\n",
    "        iterations_per_loop=1000,\n",
    "        num_shards=8,\n",
    "        per_host_input_for_training=is_per_host))\n",
    "\n",
    "# 메소드 편하게 쓰기위한 파라미터 세팅\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    init_checkpoint=init_checkpoint,\n",
    "    learning_rate=learning_rate,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    use_tpu=use_tpu,\n",
    "    use_one_hot_embeddings=use_tpu)\n",
    "\n",
    "# TPU를 쓸거면 TPU 설정을 하고, TPU가 없다면, 로컬 세팅을 설정하게 됨.\n",
    "# 학습해야할 모델을 model_fn을 통해 bert로 설정한다. (modeling 클래스의 제공되는 BERT Archi)\n",
    "estimator = tf.estimator.tpu.TPUEstimator(\n",
    "    use_tpu=use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=train_batch_size,\n",
    "    eval_batch_size=eval_batch_size)\n",
    "\n",
    "if do_train:\n",
    "    # masked된 여러 샘플들을 계속 배치수만큼 꺼내서 estimator에 선언된 모델로 학습을 진행시킨다.\n",
    "    tf.logging.info(\"***** Running training *****\")\n",
    "    tf.logging.info(\"  Batch size = %d\", train_batch_size)\n",
    "    train_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=max_seq_length,\n",
    "        max_predictions_per_seq=max_predictions_per_seq,\n",
    "        is_training=True)\n",
    "    estimator.train(input_fn=train_input_fn,\n",
    "                    max_steps=num_train_steps)\n",
    "\n",
    "if do_eval:\n",
    "    tf.logging.info(\"***** Running evaluation *****\")\n",
    "    tf.logging.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    # 순서대로 그냥 만들어놓은 tfrecode값을 가져와서 하나하나 bert모델을 검증하게된다.\n",
    "    eval_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=max_seq_length,\n",
    "        max_predictions_per_seq=max_predictions_per_seq,\n",
    "        is_training=False)\n",
    "    # 모델 검증\n",
    "    result = estimator.evaluate(\n",
    "        input_fn=eval_input_fn, steps=max_eval_steps)\n",
    "    # 검증결과 저장\n",
    "    output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
    "    # pre-trained 모델 저장\n",
    "    with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
    "        tf.logging.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87747e323cc7882d2125ceeae21403cbedd3fe1be12a04e1835bb5c26a1c0d81"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
